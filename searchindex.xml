<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>情报库AI引擎 (二)建立多线程爬虫提升爬取速度</title><url>https://yeplain.xyz/post/ai2/</url><categories><category>python</category></categories><tags><tag>python</tag></tags><content type="html">
需求：现有的情报库来源均为第三方接口，需要通过这些原始数据，基于深度学习网络，构建能够实现自动检测的恶意网址识别模型。首先需要通过爬虫，挖掘三百多万条恶意网址的信息，并进行标签化，从而构建原始的数据集。
由于单线程爬取速度慢，因此进行了改进，实现多线程爬取数据。
基于python中的requests、beautifulSoup等库，编写了初步的爬虫脚本如下：
经过分析我发现，大部分的恶意网站可以通过其title和链接的名字判断出来，基于此，我们爬取每一个网站的 ‘title’ 和 ‘a&rsquo;，并将其存入文件中。
进一步，使用threading库，构建10个线程，并通过锁约束行号，避免冲突
实现代码如下：
# coding=utf-8 import threading import time import requests from bs4 import BeautifulSoup from lxml import etree import logging import pandas as pd import xlrd import xlwt row = 1 def craw_url(url): global row try: resp = s.get('https://'+url, verify=False, timeout=2) except: try: resp = s.get('http://' + url, verify=False, timeout=2) except: # print('%s url get error happened' % url) return -1 resp.encoding = "utf-8" if resp.status_code != 200: # print('%s url 不可正常访问' % url) return -1 html = resp.text bes = BeautifulSoup(html, 'lxml') a_list = bes.find_all('a') title = bes.find('title') if title is not None: if title.string == "江苏反诈公益宣传": return -1 sheet.write(row, 1, title.string) print(title.string) link_info = [] for a in a_list: if a.string is None: continue link_info.append(a.string) if len(link_info) > 0: sheet.write(row, 2, str(link_info)) if (title is not None) or (len(link_info) > 0): print(url) sheet.write(row, 0, url) print('--------------This is No.%d significantly url--------------' % row) lock.acquire() row += 1 lock.release() return 1 else: # print('no info in this url') return -1 if __name__ == '__main__': start = time.perf_counter() requests.adapters.DEFAULT_RETRIES = 5 s = requests.session() s.keep_alive = False # read urls from the xlsx file data = xlrd.open_workbook(r'D:\shixi\model\traffic_target_1-1.xlsx') table = data.sheets()[0] urls = table.col_values(0) # write features_original to the xlsx file book = xlwt.Workbook(encoding='utf-8', style_compression=0) sheet = book.add_sheet('features_ori', cell_overwrite_ok=True) col = ('url', 'title', 'features_ori') # anti-anti-spider headers = { 'User-Agent': "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)z \ Chrome/103.0.0.0 Safari/537.36", 'Cookie': "buvid3=0C3F9901-0B4A-20F7-B743-F39956A904E533362infoc; innersign=0'"} s.headers = headers logging.captureWarnings(True) # 多线程 lock = threading.Lock() max_connections = 60 pool_sema = threading.BoundedSemaphore(max_connections) thread_list = [] for url in urls: pool_sema.acquire() thread = threading.Thread(target=craw_url, args=[url]) thread.start() pool_sema.release() thread_list.append(thread) #ret = craw_url(url, i) # if ret == 1: # i += 1 for t in thread_list: t.join() book.save('features_ori_new2.xls') print("+++++++++++++++Original Features Mining Finished+++++++++++++++") 结果示例如下：
构建了60个线程，爬取速度得到了飞速提升</content></entry><entry><title>情报库AI引擎 (一)通过爬虫建立原始数据集</title><url>https://yeplain.xyz/post/ai1/</url><categories><category>python</category></categories><tags><tag>python</tag></tags><content type="html">
需求：现有的情报库来源均为第三方接口，需要通过这些原始数据，基于深度学习网络，构建能够实现自动检测的恶意网址识别模型。首先需要通过爬虫，挖掘三百多万条恶意网址的信息，并进行标签化，从而构建原始的数据集。
基于python中的requests、beautifulSoup等库，编写了初步的爬虫脚本如下：
经过分析我发现，大部分的恶意网站可以通过其title和链接的名字判断出来，基于此，我们爬取每一个网站的 ‘title’ 和 ‘a&rsquo;，并将其存入文件中。
实现代码如下：
# coding=utf-8 import requests from bs4 import BeautifulSoup from lxml import etree import logging import pandas as pd import xlrd import xlwt requests.adapters.DEFAULT_RETRIES = 5 s = requests.session() s.keep_alive = False # read urls from the xlsx file data = xlrd.open_workbook(r'D:\shixi\model\traffic_target_1-1.xlsx') table = data.sheets()[0] urls = table.col_values(0) # write features_original to the xlsx file book = xlwt.Workbook(encoding='utf-8', style_compression=0) sheet = book.add_sheet('features_ori', cell_overwrite_ok=True) col = ('url', 'title', 'features_ori', 'features_more') # anti-anti-spider headers = { 'User-Agent': "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)z \ Chrome/103.0.0.0 Safari/537.36", 'Cookie': "buvid3=0C3F9901-0B4A-20F7-B743-F39956A904E533362infoc; innersign=0'"} s.headers = headers logging.captureWarnings(True) i = 1 # 行号 for url in urls: try: resp = s.get('https://'+url, verify=False, timeout=2) except: try: resp = s.get('http://' + url, verify=False, timeout=2) except: print('%s url get error happened' % url) continue resp.encoding = "utf-8" if resp.status_code != 200: print('%s url 不可正常访问' % url) continue html = resp.text bes = BeautifulSoup(html, 'lxml') a_list = bes.find_all('a') title = bes.find('title') print(url) if title is not None: if title.string == "江苏反诈公益宣传": continue print(title.string) sheet.write(i, 1, title.string) link_info = [] for a in a_list: if a.string is None: continue link_info.append(a.string) if len(link_info) > 0: sheet.write(i, 2, str(link_info)) if (title is not None) | (len(link_info) > 0): sheet.write(i, 0, url) print('--------------This is No.%d significantly url--------------' %i) i += 1 book.save('features_ori_new.xls') 结果示例如下：</content></entry><entry><title>实习产出Internship outputs</title><url>https://yeplain.xyz/post/internship_outputs/</url><categories><category>internship</category></categories><tags><tag>internship</tag></tags><content type="html">
更新记录一下实习产出~
一、优化流量平台服务 优化主流程中本地名单验证时，需要读取数据库的问题 取消本地验证名单时读mysql的操作，仅保留读redis的操作
更改redis上名单相关的ttl为永久，保证主流程的命中情况
缓存服务本地库更新问题 对定时更新本地失陷名单的方法进行补充，增添了对各名单中条目来源的判断（腾讯/安恒），并定时调用各自的API进行更新
二、 优化插件平台服务 网关扫描次数统计问题 对cacheHeartbeat新增ScanTimes，在扫描结束时增加对设备缓存的判断，在成功结束后，对扫描次数进行统计，并写入对应的gateway表中
新增查找出现故障插件功能 在每次心跳开始时对Plugin重启时间进行判定，从而找出出现故障（即重启过）的插件，及其对应的产品型号，写入缓存 新增对数据库gateway表中对heartbeat_time字段的增删查改 新增在线网关统计功能 在心跳时将该网关加入缓存的在线网关有序集合，以时间戳为score进行记录； 定时5s获取在线网关数，并将其纳入监控项送入Prometheus展示； 修改插件版本更新数量限制实现方式 使用ZSet对版本更新的数量变化进行记录，score初始设置为定值，随着版本更新修改对应插件已更新数量，从而可以在Redis中动态地进行观测； 新增扫描结果记录功能 添加scan_gateway, scan_device, scan_cpe 三张表，用于存储扫描结果；
在finish_ gateway _scan 方法中，通过request数据中的网关mac与pppoe在gateway表中查询对应的id，将其与此时记录的时间存入scan_gateway表中；
再通过gatewayMac和pppoe查询在扫描设备列表时记录的缓存数据，根据查到的deivceMac在device表中查询对应的id与type，将其存入scan_device表中；
在存cpe信息时，发现由于此前在match_probe方法中，未对cpe信息进行保存，缓存中只有leak相关信息，因此在match_probe中添加一个Redis哈希表来记录每台设备的各个端口对应的cpe相关信息;
进而回到finish_ gateway _scan 方法中，对设备的每一个端口，通过在缓存中查询得到的对应的cpe相关信息，在cpe表中查询对应的cpeId，将其和端口、服务等信息存入scan_cpe表中；
上述三个表通过scan_id、scan_device_id进行关联，需要保证参照完整性；
优化Ping_failed请求处理方式 现有处理方式： 在每次接收到ping_failed请求后，在Redis对对应设备的string key, value +1，当大于等于10次后，返回“不要再扫描”的回复，并异步执行updatePingFailedDeviceStatus，删除Redis中对应key, 并将数据库中设备IsDisablePing字段设置为1；
现有问题：由于updatePingFailedDeviceStatus方法中直接将缓存清空，所以对于某些一直无法ping通的设备，每一轮扫描时，都需要对该设备ping10次才能停止扫描，浪费了大量时间；
解决方法：在updatePingFailedDeviceStatus中，不再直接删除该key，而是通过在外部设置TTL，使得一段时间内收到该设备的ping_failed后，都直接返回停止扫描，提高qps；
三、问题研究与报告撰写 流量平台服务中gRPC负载均衡失效问题研究 k8s中，由于gRPC框架基于HTTP2.0，会出现负载均衡失效的问题，对该问题进行了研究，找到对应的解决方案并撰写了相关报告
高危端口及解决方案研究 对135、139、445三个高危端口的概念、漏洞风险以及关闭和开启方法进行学习研究，并撰写报告提交
Redis与Mysql一致性问题研究 流量平台中各类名单同时存储在Redis及Mysql数据库中，因此需要保证二者的一致性，对其一致性实现方式进行了学习并撰写了相关报告
撰写流量平台业务流程说明文档 将流量平台的业务通过流程图可视化，并撰写文档解释说明
撰写云宽带-安全方案文档 介绍我们的业务能力，以及简要的流程
制作威胁情报库slide 分析展示威胁情报库能力
四、为所有服务端增添Prometheus监控 对现有的四个服务：traffic-report-server、traffic-cache-server、traffic-context-consumer、probe-server-refactor添加Prometheus监控，连接grafana对统计信息进行图形化动态输出
Probe-server添加监控 分别使用gauge和counter数据类型对总访问次数、正常访问次数、正常返回次数、TCP各个方法调用次数、在线网关数添加Prometheus监控
五、对服务监控定位 通过kubectl对probe-server的pods进行监控 监控K8s下的probe-server的Pods, 出现问题时及时反馈，并通过日志定位
通过pprof对出错位置定位 学习pprof的使用方式，通过它来对生产环境中出现的问题进行定位
六、其他 解析生成旧版plugin_name对照表 通过向probe-server原始版本的服务发送请求，分析返回的内容，得到product_class，probe_version与plugin_name的对照表</content></entry><entry><title>python爬虫访问时遇到ProxyErr问题记录</title><url>https://yeplain.xyz/post/python-err/</url><categories><category>python</category></categories><tags><tag>python</tag></tags><content type="html"> 爬取信息时，通过get建立连接，但一直出现proxyErr问题，最终定位解决
一开始以为是代理的问题，但是用浏览器可以正常访问
最后发现是库版本的问题
在原报错环境中使用下面命令重装低版本 urllib3：
pip install urllib3==1.25.11 然后测试果然就没问题了
同样遭遇代理错误的 pip
同样是在这个环境中，也遇到了 pip install 安装包失败的问题，报错信息是：
'ProxyError('Cannot connect to proxy.', FileNotFoundError(2, 'No such file or directory'))'
于是继续对比版本包，结果在 pip 包的路径下发现有一个 _vendor\urllib3 目录，原来 pip 是直接把 urllib3 集成到了自己的包里面，不受系统安装包的影响。检查其中的 _version.py 里的版本信息，果然也是 1.26.x。
出错的 pip 的版本是 20.3，把 pip 也降级到 20.2 以下，就没有问题了。</content></entry><entry><title>golang restful 框架之 go-swagger</title><url>https://yeplain.xyz/post/go-swagger/</url><categories><category>golang</category></categories><tags><tag>swagger</tag></tags><content type="html">
需求：实习中，我们新版本探针的下发使用的是直接调用scan-apiserver接口的方式，现在需要新增加一个服务scan-scheduler，来对下载任务进行管控，需要使用swagger。
什么是Restful风格 概念 Restful风格指的是网络应用中就是资源定位和资源操作的风格。不是标准也不是协议。 Rest即Representational State Transfer的缩写，可译为"表现层状态转化”。Restful风格最大的特点为：资源、统一接口、URI和无状态。 这种风格设计的软件，可以更简洁，更有层次，更易于实现缓存等机制。
基于HTTP，可以使用 XML 格式定义或 JSON 格式定义。
特点 资源：互联网所有的事务都可以被抽象为资源，例如：.txt .html .jpg .mp3 .mp4等 RESTful 架构风格是围绕资源展开的，资源操作都是统一接口的： GET（SELECT）：从服务器取出资源（一项或多项）。 POST（CREATE）：在服务器新建一个资源。 PUT（UPDATE）：在服务器更新资源（客户端提供完整资源数据）。 PATCH（UPDATE）：在服务器更新资源（客户端提供需要修改的资源数据）。 DELETE（DELETE）：从服务器删除资源。 URI：每一个URI（统一资源定位符）指向一个特定的资源。通过URI来访问资源。最典型的URI就是URL。@RequestMapping的path/value属性表示的就是URL的一部分。 无状态：所有的资源，都可以通过URI定位，而且这个定位与其他资源无关。例如无需登录就可以通过URL查看，就是无状态。需要登录才能查看，是有状态。
操作资源方式 传统 http://127.0.0.1/item/queryUser.action?id=1 查询,GET http://127.0.0.1/item/saveUser.action 新增,POST http://127.0.0.1/item/updateUser.action 更新,POST http://127.0.0.1/item/deleteUser.action?id=1 删除,GET或POST
Restful 【GET】 /users # 查询用户信息列表
【GET】 /users/1001 # 查看某个用户信息
【POST】 /users # 新建用户信息
【PUT】 /users/1001 # 更新用户信息(全部字段)
【PATCH】 /users/1001 # 更新用户信息(部分字段)
【DELETE】 /users/1001 # 删除用户信息
之前的操作每次请求的接口或者地址,都在做描述,例如查询的时候用了queryUser,新增的时候用了saveUser ，修改的时候用了updateUser,其实完全没有这个必要, 使用了get请求,就是查询.使用post请求,就是新增的请求,PUT就是修改，delete就是删除，
意图很明显,完全没有必要做描述,这就是为什么有了restful.
go swagger restful 是这些年的高频词汇了，各大互联网公司也都纷纷推出了自己的 restful api，其实 restful 和 thrift，grpc 类似，就是一种协议，但是这种协议有点特殊的就是使用 http 接口，返回的对象一般是 json 格式，这样有个好处，就是可以供前端的 js 直接调用，使用非常方便，但 http 本身并不是一个高效的协议，后端的内部通信还是使用 grpc 或者 thrift 可以获得更高的性能
其实如果只是要用 http 返回 json 本身并不是一件很难的事情，不用任何框架，golang 本身也能很方便做到，但是当你有很多 api 的时候，这些 api 的维护和管理就会变得很复杂，你自己都无法记住这些 api 应该填什么参数，返回什么，当然你可以花很多时间去维护一份接口文档，这样不仅耗时而且很难保证文档的即时性，准确性以及一致性
swagger 有一整套规范来定义一个接口文件，类似于 thrift 和 proto 文件，定义了服务的请求内容和返回内容，同样也有工具可以生成各种不同语言的框架代码，在 golang 里面我们使用 go-swagger 这个工具，这个工具还提供了额外的功能，可以可视化显示这个接口，方便阅读
go-swagger使用方法 api定义文件 首先需要写一个 api 定义文件
swagger: '2.0' info: description: 不想依赖第三方的统计和评论，自己开发一个点赞评论系统 version: 1.0.0 title: comment_like contact: email: hatlonely@foxmail.com license: name: Apache 2.0 url: 'http://www.apache.org/licenses/LICENSE-2.0.html' host: hatlonely.com basePath: /api tags: - name: view description: 浏览 - name: like description: 点赞 - name: comment description: 评论 schemes: - http paths: /doview: get: tags: - view summary: 浏览 description: '' operationId: doView consumes: - application/json produces: - application/json parameters: - name: title in: query description: 文章标题 required: true type: string responses: '200': description: 成功 schema: $ref: '#/definitions/ErrorModel' '500': description: 内部错误 schema: $ref: '#/definitions/ErrorModel' /countview: get: tags: - view summary: 浏览 description: '' operationId: countView consumes: - application/json produces: - application/json parameters: - name: title in: query description: 文章标题 required: true type: string responses: '200': description: 成功 schema: $ref: '#/definitions/CountViewModel' '500': description: 内部错误 schema: $ref: '#/definitions/ErrorModel' /dolike: get: tags: - like summary: 点赞 description: '' operationId: doLike consumes: - application/json produces: - application/json parameters: - name: title in: query description: 文章标题 required: true type: string responses: '200': description: 成功 schema: $ref: '#/definitions/ErrorModel' '500': description: 内部错误 schema: $ref: '#/definitions/ErrorModel' /dounlike: get: tags: - like summary: 取消赞 description: '' operationId: doUnlike consumes: - application/json produces: - application/json parameters: - name: title in: query description: 文章标题 required: true type: string responses: '200': description: 成功 schema: $ref: '#/definitions/ErrorModel' '500': description: 内部错误 schema: $ref: '#/definitions/ErrorModel' /showlike: get: tags: - like summary: 点赞否 description: '' operationId: showLike consumes: - application/json produces: - application/json parameters: - name: title in: query description: 文章标题 required: true type: string responses: '200': description: 成功 schema: $ref: '#/definitions/ShowLikeModel' '500': description: 内部错误 schema: $ref: '#/definitions/ErrorModel' /countlike: get: tags: - like summary: 有多少赞 description: '' operationId: countLike consumes: - application/json produces: - application/json parameters: - name: title in: query description: 文章标题 required: true type: string responses: '200': description: 成功 schema: $ref: '#/definitions/CountLikeModel' '500': description: 内部错误 schema: $ref: '#/definitions/ErrorModel' /docomment: get: tags: - comment summary: 评论 description: '' operationId: doComment consumes: - application/json produces: - application/json parameters: - name: title in: query description: 文章标题 required: true type: string - name: content in: query description: 评论内容 required: true type: string - name: nickname in: query description: 用户昵称 required: false type: string - name: mail in: query description: 用户邮箱 required: false type: string responses: '200': description: 成功 schema: $ref: '#/definitions/ErrorModel' '500': description: 内部错误 schema: $ref: '#/definitions/ErrorModel' /showcomment: get: tags: - comment summary: 显示评论 description: '' operationId: showComment consumes: - application/json produces: - application/json parameters: - name: title in: query description: 文章标题 required: true type: string responses: '200': description: 成功 schema: $ref: '#/definitions/ShowCommentModel' '500': description: 内部错误 schema: $ref: '#/definitions/ErrorModel' definitions: CountViewModel: type: object properties: count: type: integer title: type: string example: golang json 性能分析 ShowLikeModel: type: object properties: ip: type: string example: 127.0.0.1 ua: type: string example: >- Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36 title: type: string example: golang json 性能分析 islike: type: boolean CountLikeModel: type: object properties: count: type: integer title: type: string example: golang json 性能分析 ShowCommentModel: type: object properties: comments: type: array items: $ref: '#/definitions/CommentModel' CommentModel: type: object properties: content: type: string example: 写得很好 nickname: type: string example: sonic mail: type: string example: sonic@foxmail.com ErrorModel: type: object properties: message: type: string example: error message code: type: integer example: 400 这个是 yaml 语法，有点像去掉了括号的 json
这里完整地定义了请求方法、请求参数、正常返回接口、异常返回结果，有了这个文件只需要执行下面命令就能生成框架代码了
swagger generate server -f api/comment_like/comment_like.yaml 还可以下面这个命令可视化查看这个接口文件
swagger serve api/comment_like/comment_like.yaml 这个命令依赖 swagger 工具，可以通过下面命令获取
go get -u github.com/go-swagger/go-swagger/cmd/swagger export PATH=$GOPATH/bin:$PATH 执行完了之后，你发现多了几个文件夹，其中 cmd 目录里面包含 main 函数，是整个程序的入口，restapi 文件夹下面包含协议相关代码，其中 configure_xxx.go 是需要特别关注的，你需要在这个文件里面实现你具体的业务逻辑
现在你就其实已经可以运行程序了，go run cmd/comment-like-server/main.go，在浏览器里面访问一下你的 api，会返回一个错误信息，告诉你 api 还没有实现，下面就来实现一下吧
api.LikeCountLikeHandler = like.CountLikeHandlerFunc(func(params like.CountLikeParams) middleware.Responder { count, err := comment_like.CountLike(params.Title) if err != nil { return like.NewCountLikeInternalServerError().WithPayload(&amp;models.ErrorModel{ Code: http.StatusInternalServerError, Message: err.Error(), }) } return like.NewCountLikeOK().WithPayload(&amp;models.CountLikeModel{ Count: count, Title: params.Title, }) }) 你只需要在这些 handler 里面实现自己的业务逻辑即可，这里对协议的封装非常好，除了业务逻辑以及打包返回，没有多余的逻辑
再次运行，现在返回已经正常了
统一处理 如果你对请求有一些操作需要统一处理，比如输出统一的日志之类的，可以重写这个函数，也在 configure_xxx.go 这个文件中
func setupGlobalMiddleware(handler http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { w.Header().Set("Access-Control-Allow-Origin", "*") handler.ServeHTTP(w, r) }) }</content></entry><entry><title>网关Gateway与路由器Router的区别</title><url>https://yeplain.xyz/post/gatewayrouter/</url><categories><category>basic</category></categories><tags><tag>basic</tag></tags><content type="html">
“网关”是一个概念，“路由器”是一个产品。
路由器可以做网关，防火墙
可以做网关，三层交换机可以做网关，一台普通pc可以做网关，甚至一个智能手机也可以做网关。
这要从上世纪80年代说起。
咱们现在，情侣之间要不停的保持联系，超过几小时没发消息，女孩子就会想这个男生是不是沾花惹草了，当然现在有微信、QQ等各种很方便的即时通信工具。
但是上世纪80年代，哪里有这种先进的工具，当时电话费都及其高昂，网络技术也是刚刚出现，还没有统一的成熟的标准。斯坦福两个不同系的奥纳多•波萨克（Leonard Bosack）和桑迪•勒纳（Sandy Lerner）互发情书就很不方便。
当时不同的组织采用不同的网络协议，只能内部通信，不能互通，不像现在tcp/ip一统天下。
然后这两位超级学霸，就发明了路由器，路由器可以用来连接不同的网络。
路由器也成为了两个网络的“网关”，帮两个不同网络进行数据转发。
上面两位是思科公司的创始人，思科因为路由器发展成全球最大的公司之一。
故事看到这里，网关的作用就已经清晰了，就是帮助两个不能直接互通的网络，进行数据转发的。
所以。
路由器可以做网关，把家庭局域网和互联网相连。
手机可以做网关，手机开了热点，笔记本接进来，手机作为网关把笔记本和互联网相连。
防火墙可以做网关，局域网连到防火墙，防火墙把局域网和互联网相连，顺便还能抵抗各种攻击。
总而言之，
网关是网络中的一个角色，指的是一个“网络”中的出口
路由器是一种设备
路由器可以实现网关的功能，但是路由器功能不仅仅是实现网关
网关可以由路由器实现，但是也不仅仅是由路由器实现</content></entry><entry><title>Telnet与SSH区别，以及nc等命令</title><url>https://yeplain.xyz/post/sshtelnet/</url><categories><category>linux</category></categories><tags><tag>linux</tag></tags><content type="html">
实习中通过ssh telnet 连接测试环境和生产环境，还使用nc命令测试数据发送
首先，telnet和ssh都是连接远程计算机的连接协议，可以完成对完成计算机的控制，方便维护。其次，他们都是基于TCP/IP协议下的，所以连接时都需要知道目标机的网址或者域名，第三，他们都是与远程主机连接的通道，完成的目的是一样的，只不过手段不一样而已。
Telnet Telnet连接计算机需要如下几个过程：
客户端建立与远程主机的TCP连接；远程机通知客户机收到连接，等候输入；客户机收到通知后收集用户输入，将输入的字符串变成标准格式并传送给远程机；远程机接受输入的命令，并执行，将得到的结果输出给客户机；客户机在收到回显后显示在界面上。
值得注意的是，telnet连接的时候直接建立TCP连接，所有传输的数据都是明文传输，所以是一种不安全的方式。
SSH SSH 为Secure Shell的缩写，SSH 为建立在应用层基础上的安全协议，是比较可靠安全的协议。
版本号协商阶段，SSH目前包括 SSH1和SSH2两个版本，双方通过版本协商确定使用的版本
密钥和算法协商阶段，SSH支持多种加密算法，双方根据本端和对端支持的算法，协商出最终使用的算法
认证阶段，SSH客户端向服务器端发起认证请求，服务器端对客户端进行认证
会话请求阶段，认证通过后，客户端向服务器端发送会话请求
交互会话阶段，会话请求通过后，服务器端和客户端进行信息的交互
值得注意的是，由于ssh经过加密算法加密，收报文需要解密，发报文需要加密，导致其传输速度、效率较telnet低很多，然而，它却有telnet不具有的安全性。
在使用SSH的时候，一个数字证书将认证客户端(你的工作站)和服务器(你的网络设备)之间的连接，并加密受保护的口令。SSH1使用RSA加密密钥，SSH2使用数字签名算法(DSA)密钥保护连接和认证。加密算法包括Blowfish，数据加密标准(DES)，以及三重DES(3DES)。SSH保护并且有助于防止欺骗，“中间人”攻击，以及数据包监听。 通过使用SSH把所有传输的数据进行加密，这样“中间人”这种攻击方式就不可能实现了，而且也能够防止DNS和IP欺骗。还有一个额外的好处就是传输的数据是经过压缩的，所以可以加快传输的速度。SSH有很多功能，它既可以代替telnet，又可以为ftp、pop、甚至ppp提供一个安全的“通道”。
ssh root@192.168.2.200 nc nc 127.0.0.1 9092 nc命令的作用： 实现任意TCP/UDP端口的侦听，nc可以作为server以TCP或UDP方式侦听指定端口 端口的扫描，nc可以作为client发起TCP或UDP连接 机器之间传输文件 机器之间网络测速 参数：
-l 用于指定nc将处于侦听模式。指定该参数，则意味着nc被当作server，侦听并接受连接，而非向其它地址发起连接。 -p 暂未用到（老版本的nc可能需要在端口号前加-p参数，下面测试环境是centos6.6，nc版本是nc-1.84，未用到-p参数） -s 指定发送数据的源IP地址，适用于多网卡机 -u 指定nc使用UDP协议，默认为TCP -v 输出交互或出错信息，新手调试时尤为有用 -w 超时秒数，后面跟数字 nc后，作为client，发送：
server收到后，查看日志：</content></entry><entry><title>K8s原理与kubectl</title><url>https://yeplain.xyz/post/k8s/</url><categories><category>K8s</category></categories><tags><tag>k8s</tag></tags><content type="html">
Kubernetes 这个名字源于希腊语，意为“舵手”或“飞行员”，简称 k8s，8代表中间的八个字符 Google 在 2014 年开源了 Kubernetes 项目，是Google基于Borg开源的容器编排调度引擎。
在实习中，需要对probe-server的各个容器的状态进行监控，从而尽早定位问题，解决问题。
介绍 DevOps DevOps（Development和Operations的组合词）是一组过程、方法与系统的统称，用于促进开发（应用程序/软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。
它是一种重视“软件开发人员（Dev）”和“IT运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。
它的出现是由于软件行业日益清晰地认识到：为了按时交付软件产品和服务，开发和运营工作必须紧密合作。
应用部署方式的演变 在部署应用程序的方式上，主要经历了三个时代：
传统部署：互联网早期，会直接将应用程序部署在物理机上 ​ 优点：简单，不需要其它技术的参与
​ 缺点：不能为应用程序定义资源使用边界，很难合理地分配计算资源，而且程序之间容易产生影响
虚拟化部署：可以在一台物理机上运行多个虚拟机，每个虚拟机都是独立的一个环境 ​ 优点：程序环境不会相互产生影响，提供了一定程度的安全性
​ 缺点：增加了操作系统，浪费了部分资源
容器化部署：与虚拟化类似，但是共享了操作系统 ​ 优点：
​ 可以保证每个容器拥有自己的文件系统、CPU、内存、进程空间等
​ 运行应用程序所需要的资源都被容器包装，并和底层基础架构解耦
​ 容器化的应用程序可以跨云服务商、跨Linux操作系统发行版进行部署
容器化部署方式给带来很多的便利，但是也会出现一些问题，比如说：
一个容器故障停机了，怎么样让另外一个容器立刻启动去替补停机的容器 当并发访问量变大的时候，怎么样做到横向扩展容器数量 这些容器管理的问题统称为容器编排问题，为了解决这些容器编排问题，就产生了一些容器编排的软件：
​ Swarm：Docker自己的容器编排工具 ​ Mesos：Apache的一个资源统一管控的工具，需要和Marathon结合使用 ​ Kubernetes：Google开源的的容器编排工具
kubernetes的本质是一组服务器集群，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理。目的是实现资源管理的自动化，主要提供了如下的主要功能：
​ 自我修复：一旦某一个容器崩溃，能够在1秒中左右迅速启动新的容器 ​ 弹性伸缩：可以根据需要，自动对集群中正在运行的容器数量进行调整 ​ 服务发现：服务可以通过自动发现的形式找到它所依赖的服务 ​ 负载均衡：如果一个服务起动了多个容器，能够自动实现请求的负载均衡 ​ 版本回退：如果发现新发布的程序版本有问题，可以立即回退到原来的版本 ​ 存储编排：可以根据容器自身的需求自动创建存储卷
kubernetes组件 一个kubernetes集群主要是由控制节点(master)、**工作节点(node)**构成，每个节点上都会安装不同的组件。
master 集群的控制平面，负责集群的决策 ( 管理 )
ApiServer : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制 Scheduler : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上 ControllerManager : 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等 Etcd ：负责存储集群中各种资源对象的信息 node 集群的数据平面，负责为容器提供运行环境 ( 干活 )
Kubelet : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器 KubeProxy : 负责提供集群内部的服务发现和负载均衡 Docker : 负责节点上容器的各种操作 其他 Master：集群控制节点，每个集群需要至少一个master节点负责集群的管控
Node：工作负载节点，由master分配容器到这些node工作节点上，然后node节点上的docker负责容器的运行
Pod：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器
Controller：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等
Service：pod对外服务的统一入口，下面可以维护者同一类的多个pod
Label：标签，用于对pod进行分类，同一类pod会拥有相同的标签
NameSpace：命名空间，用来隔离pod的运行环境
node、pod、container，service之间的关系 在Kubernetes中，最小的管理元素不是一个个独立的容器，而是Pod
Pod是最小的，管理，创建，计划的最小单元.
一个Pod相当于一个共享context的配置组，在同一个context下，应用可能还会有独立的cgroup隔离机制，一个Pod是一个容器环境下的“逻辑主机”，它可能包含一个或者多个紧密相连的应用，这些应用可能是在同一个物理主机或虚拟机上。
同一个Pod中的应用可以共享磁盘，磁盘是Pod级的，应用可以通过文件系统调用。
Node是Pod真正运行的主机，可以物理机，也可以是虚拟机。
当我们讨论 k8s 时总是会讨论集群，k8s 中的每个集群由多个机器/虚拟机组成，集群也被称为 命名空间(namespace)，命名空间是虚拟的，因此也叫虚拟集群。
Namespace 是对一组资源和对象的抽象集合。
node 是集群中的单个机器/虚拟机，node 有两种，一种是 master ，一种是 worker。master 用来运行 kubernetes 服务，例如 API Server；worker 是真正工作的节点，用来运行你的容器。
master 节点控制其它节点，向 worker 节点发送消息，将工作分配给他们，worker 节点向 master 节点汇报工作。
每个节点上运行着多个服务，有时 服务A 和 服务B 是关联起来的，需要一起启动一起注销，那么可以设置为一个 pod。pod 是逻辑分组，是 k8s 中独立的、隔离的最小的工作单元。pod 中可以有一个或多个容器/服务，pod 允许你把多个容器结合起来，指导这些容器如何组合创建应用程序。
多个 pod 可以组成一个 service ，service 提供了一个单一的 IP 地址和 DNS 名称，可以通过它访问 service 内的所有 pod。有了 service 我们可以很容易的设置和管理负载均衡。
kubectl 1. namespace Namespace是kubernetes系统中的一种非常重要资源，它的主要作用是用来实现多套环境的资源隔离或者多租户的资源隔离。
默认情况下，kubernetes集群中的所有的Pod都是可以相互访问的。但是在实际中，可能不想让两个Pod之间进行互相的访问，那此时就可以将两个Pod划分到不同的namespace下。kubernetes通过将集群内部的资源分配到不同的Namespace中，可以形成逻辑上的"组"，以方便不同的组的资源进行隔离使用和管理。
可以通过kubernetes的授权机制，将不同的namespace交给不同租户进行管理，这样就实现了多租户的资源隔离。此时还能结合kubernetes的资源配额机制，限定不同租户能占用的资源，例如CPU使用量、内存使用量等等，来实现租户可用资源的管理。
[root@master ~]# kubectl get namespace NAME STATUS AGE default Active 45h # 所有未指定Namespace的对象都会被分配在default命名空间 kube-node-lease Active 45h # 集群节点之间的心跳维护，v1.13开始引入 kube-public Active 45h # 此命名空间下的资源可以被所有人访问（包括未认证用户） kube-system Active 45h # 所有由Kubernetes系统创建的资源都处于这个命名空间 查看 # 1 查看所有的ns 命令：kubectl get ns [root@master ~]# kubectl get ns NAME STATUS AGE default Active 45h kube-node-lease Active 45h kube-public Active 45h kube-system Active 45h # 2 查看指定的ns 命令：kubectl get ns ns名称 [root@master ~]# kubectl get ns default NAME STATUS AGE default Active 45h # 3 指定输出格式 命令：kubectl get ns ns名称 -o 格式参数 # kubernetes支持的格式有很多，比较常见的是wide、json、yaml [root@master ~]# kubectl get ns default -o yaml apiVersion: v1 kind: Namespace metadata: creationTimestamp: "2021-05-08T04:44:16Z" name: default resourceVersion: "151" selfLink: /api/v1/namespaces/default uid: 7405f73a-e486-43d4-9db6-145f1409f090 spec: finalizers: - kubernetes status: phase: Active # 4 查看ns详情 命令：kubectl describe ns ns名称 [root@master ~]# kubectl describe ns default Name: default Labels: &lt;none> Annotations: &lt;none> Status: Active # Active 命名空间正在使用中 Terminating 正在删除命名空间 # ResourceQuota 针对namespace做的资源限制 # LimitRange针对namespace中的每个组件做的资源限制 No resource quota. No LimitRange resource. 创建 # 创建namespace [root@master ~]# kubectl create ns dev namespace/dev created 删除 # 删除namespace [root@master ~]# kubectl delete ns dev namespace "dev" deleted 2.pod Pod是kubernetes集群进行管理的最小单元，程序要运行必须部署在容器中，而容器必须存在于Pod中。
Pod可以认为是容器的封装，一个Pod中可以存在一个或者多个容器。
查看 # 查看Pod基本信息 [root@master ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 43s # 查看Pod的详细信息 [root@master ~]# kubectl describe pod nginx -n dev Name: nginx Namespace: dev Priority: 0 Node: node1/192.168.5.4 Start Time: Wed, 08 May 2021 09:29:24 +0800 Labels: pod-template-hash=5ff7956ff6 run=nginx Annotations: &lt;none> Status: Running IP: 10.244.1.23 IPs: IP: 10.244.1.23 Controlled By: ReplicaSet/nginx Containers: nginx: Container ID: docker://4c62b8c0648d2512380f4ffa5da2c99d16e05634979973449c98e9b829f6253c Image: nginx:latest Image ID: docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 Port: 80/TCP Host Port: 0/TCP State: Running Started: Wed, 08 May 2021 09:30:01 +0800 Ready: True Restart Count: 0 Environment: &lt;none> Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-hwvvw (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: default-token-hwvvw: Type: Secret (a volume populated by a Secret) SecretName: default-token-hwvvw Optional: false QoS Class: BestEffort Node-Selectors: &lt;none> Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled &lt;unknown> default-scheduler Successfully assigned dev/nginx-5ff7956ff6-fg2db to node1 Normal Pulling 4m11s kubelet, node1 Pulling image "nginx:latest" Normal Pulled 3m36s kubelet, node1 Successfully pulled image "nginx:latest" Normal Created 3m36s kubelet, node1 Created container nginx Normal Started 3m36s kubelet, node1 Started container nginx 3. service 虽然每个Pod都会分配一个单独的Pod IP，然而却存在如下两问题：
Pod IP 会随着Pod的重建产生变化 Pod IP 仅仅是集群内可见的虚拟IP，外部无法访问 这样对于访问这个服务带来了难度。因此，kubernetes设计了Service来解决这个问题。
Service可以看作是一组同类Pod对外的访问接口。借助Service，应用可以方便地实现服务发现和负载均衡。
# 暴露Service [root@master ~]# kubectl expose deploy nginx --name=svc-nginx1 --type=ClusterIP --port=80 --target-port=80 -n dev service/svc-nginx1 exposed # 查看service [root@master ~]# kubectl get svc svc-nginx1 -n dev -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR svc-nginx1 ClusterIP 10.109.179.231 &lt;none> 80/TCP 3m51s run=nginx # 这里产生了一个CLUSTER-IP，这就是service的IP，在Service的生命周期中，这个地址是不会变动的 # 可以通过这个IP访问当前service对应的POD [root@master ~]# curl 10.109.179.231:80 &lt;!DOCTYPE html> &lt;html> &lt;head> &lt;title>Welcome to nginx!&lt;/title> &lt;/head> &lt;body> &lt;h1>Welcome to nginx!&lt;/h1> ....... &lt;/body> &lt;/html> 实战 实习中，需要我对probe-server的运行情况进行监控：
先看grafana曲线，若出现问题，则
kubectl get pods|grep ref #看重启 kubectl top pods|grep ref #看负载 kubectl logs [pods名] --previous --tail 100 #看日志报错 测试环境连接 ssh root@192.168.2.200 kubectl get pods kubectl exec -it probe-server-65789bfc65-c9f4q /bin/sh cd var/log/probe-server/ tail -f probe-server-65789bfc65-c9f4q.log-20220714 | grep "HeartBeat return" 另一边：
kubectl exec -it probe-server-65789bfc65-c9f4q /bin/sh
nc 127.0.0.1 9092</content></entry><entry><title>go语言中的pprof研究与应用</title><url>https://yeplain.xyz/post/pprof/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>pprof</tag></tags><content type="html">
相信很多人都听过“雷神 3”关于性能优化的故事。在一个 3D 游戏引擎的源码里，John Carmack 将 1/sqrt(x) 这个函数的执行效率优化到了极致。
因为它是最底层的函数，而游戏里涉及到大量的这种运算，使得在运算资源极其紧张的 DOS 时代，游戏也可以流畅地运行。这就是性能优化的魅力！
工作中，当业务量比较小的时候，用的机器也少，体会不到性能优化带来的收益。而当一个业务使用了几千台机器的时候，性能优化 20%，那就能省下几百台机器，一年能省几百万。省下来的这些钱，给员工发年终奖，那得多 Happy！
一般而言，性能分析可以从三个层次来考虑：应用层、系统层、代码层。
应用层主要是梳理业务方的使用方式，让他们更合理地使用，在满足使用方需求的前提下，减少无意义的调用；系统层关注服务的架构，例如增加一层缓存；代码层则关心函数的执行效率，例如使用效率更高的开方算法等。
做任何事，都要讲究方法。在很多情况下，迅速把事情最关键的部分完成，就能拿到绝大部分的收益了。其他的一些边边角角，可以慢慢地缝合。一上来就想完成 100%，往往会陷入付出了巨大的努力，却收获寥寥的境地。
性能优化这件事也一样，识别出性能瓶颈，会让我们付出最小的努力，而得到最大的回报。
Go 语言里，pprof 就是这样一个工具，帮助我们快速找到性能瓶颈，进而进行有针对性地优化。
什么是pprof 代码上线前，我们通过压测可以获知系统的性能，例如每秒能处理的请求数，平均响应时间，错误率等指标。这样，我们对自己服务的性能算是有个底。
但是压测是线下的模拟流量，如果到了线上呢？会遇到高并发、大流量，不靠谱的上下游，突发的尖峰流量等等场景，这些都是不可预知的。
线上突然大量报警，接口超时，错误数增加，除了看日志、监控，就是用性能分析工具分析程序的性能，找到瓶颈。当然，一般这种情形不会让你有机会去分析，降级、限流、回滚才是首先要做的，要先止损嘛。回归正常之后，通过线上流量回放，或者压测等手段，制造性能问题，再通过工具来分析系统的瓶颈。
一般而言，性能分析主要关注 CPU、内存、磁盘 IO、网络这些指标。
Profiling 是指在程序执行过程中，收集能够反映程序执行状态的数据。在软件工程中，性能分析（performance analysis，也称为 profiling），是以收集程序运行时信息为手段研究程序行为的分析方法，是一种动态程序分析的方法。
Go 语言自带的 pprof 库就可以分析程序的运行情况，并且提供可视化的功能。它包含两个相关的库：
runtime/pprof 对于只跑一次的程序，例如每天只跑一次的离线预处理程序，调用 pprof 包提供的函数，手动开启性能数据采集。 net/http/pprof 对于在线服务，对于一个 HTTP Server，访问 pprof 提供的 HTTP 接口，获得性能数据。当然，实际上这里底层也是调用的 runtime/pprof 提供的函数，封装成接口对外提供网络访问。 作用 pprof 是 Go 语言中分析程序运行性能的工具，它能提供各种性能数据：
allocs 和 heap 采样的信息一致，不过前者是所有对象的内存分配，而 heap 则是活跃对象的内存分配。
当 CPU 性能分析启用后，Go runtime 会每 10ms 就暂停一下，记录当前运行的 goroutine 的调用堆栈及相关数据。当性能分析数据保存到硬盘后，我们就可以分析代码中的热点了。 内存性能分析则是在堆（Heap）分配的时候，记录一下调用堆栈。默认情况下，是每 1000 次分配，取样一次，这个数值可以改变。栈(Stack)分配 由于会随时释放，因此不会被内存分析所记录。由于内存分析是取样方式，并且也因为其记录的是分配内存，而不是使用内存。因此使用内存性能分析工具来准确判断程序具体的内存使用是比较困难的。 阻塞分析是一个很独特的分析，它有点儿类似于 CPU 性能分析，但是它所记录的是 goroutine 等待资源所花的时间。阻塞分析对分析程序并发瓶颈非常有帮助，阻塞性能分析可以显示出什么时候出现了大批的 goroutine 被阻塞了。阻塞性能分析是特殊的分析工具，在排除 CPU 和内存瓶颈前，不应该用它来分析。 使用方法 我们可以通过 报告生成、Web 可视化界面、交互式终端 三种方式来使用 pprof。
runtime/pprof 拿 CPU profiling 举例，增加两行代码，调用 pprof.StartCPUProfile 启动 cpu profiling，调用 pprof.StopCPUProfile() 将数据刷到文件里：
import "runtime/pprof" var cpuprofile = flag.String("cpuprofile", "", "write cpu profile to file") func main() { // ………… pprof.StartCPUProfile(f) defer pprof.StopCPUProfile() // ………… } net/http/pprof 启动一个端口（和正常提供业务服务的端口不同）监听 pprof 请求:
import _ "net/http/pprof" func initPprofMonitor() error { pPort := global.Conf.MustInt("http_server", "pprofport", 8080) var err error addr := ":" + strconv.Itoa(pPort) go func() { err = http.ListenAndServe(addr, nil) if err != nil { logger.Error("funcRetErr=http.ListenAndServe||err=%s", err.Error()) } }() return err } pprof 包会自动注册 handler， 处理相关的请求：
// src/net/http/pprof/pprof.go:71 func init() { http.Handle("/debug/pprof/", http.HandlerFunc(Index)) http.Handle("/debug/pprof/cmdline", http.HandlerFunc(Cmdline)) http.Handle("/debug/pprof/profile", http.HandlerFunc(Profile)) http.Handle("/debug/pprof/symbol", http.HandlerFunc(Symbol)) http.Handle("/debug/pprof/trace", http.HandlerFunc(Trace)) } 启动服务后，在与生产环境建立隧道后，直接在浏览器访问：
​ http://127.0.0.1:31108/debug/pprof/
就可以得到一个汇总页面：
可以直接点击上面的链接，进入子页面，查看相关的汇总信息。
关于 goroutine 的信息有两个链接，goroutine 和 full goroutine stack dump，前者是一个汇总的消息，可以查看 goroutines 的总体情况，后者则可以看到每一个 goroutine 的状态。
点击 profile 和 trace 则会在后台进行一段时间的数据采样，采样完成后，返回给浏览器一个 profile 文件，之后在本地通过 go tool pprof 工具进行分析。
当我们下载得到了 profile 文件后，执行命令：
go tool pprof ~/Downloads/profile 就可以进入命令行交互式使用模式。执行 go tool pprof -help 可以查看帮助信息。
直接使用如下命令，则不需要通过点击浏览器上的链接就能进入命令行交互模式：
go tool pprof http://47.93.238.9:8080/debug/pprof/profile 当然也是需要先后台采集一段时间的数据，再将数据文件下载到本地，最后进行分析。上述的 Url 后面还可以带上时间参数：?seconds=60，自定义 CPU Profiling 的时长。
类似的命令还有：
# 下载 cpu profile，默认从当前开始收集 30s 的 cpu 使用情况，需要等待 30s go tool pprof http://47.93.238.9:8080/debug/pprof/profile # wait 120s go tool pprof http://47.93.238.9:8080/debug/pprof/profile?seconds=120 # 下载 heap profile go tool pprof http://47.93.238.9:8080/debug/pprof/heap # 下载 goroutine profile go tool pprof http://47.93.238.9:8080/debug/pprof/goroutine # 下载 block profile go tool pprof http://47.93.238.9:8080/debug/pprof/block # 下载 mutex profile go tool pprof http://47.93.238.9:8080/debug/pprof/mutex 进入交互式模式之后，比较常用的有 top、list、web 等命令。
执行 top 其他类型，如 heap 的 flat, sum, cum 的意义和上面的类似，只不过计算的东西不同，一个是 CPU 耗时，一个是内存大小。
执行 list 使用正则匹配，找到相关的代码
list Eat 直接定位到了相关长耗时的代码处：
执行 web （需要安装 graphviz，pprof 能够借助 grapgviz 生成程序的调用图），会生成一个 svg 格式的文件，直接在浏览器里打开（可能需要设置一下 .svg 文件格式的默认打开方式）
go tool pprof http:// localhost:31108/debug/pprof/profile 图中的连线代表对方法的调用，连线上的标签代表指定的方法调用的采样值（例如时间、内存分配大小等），方框的大小与方法运行的采样值的大小有关。
每个方框由两个标签组成：在 cpu profile 中，一个是方法运行的时间占比，一个是它在采样的堆栈中出现的时间占比（前者是 flat 时间，后者则是 cumulate 时间占比)；框越大，代表耗时越多或是内存分配越多。
另外，traces 命令还可以列出函数的调用栈
除了上面讲到的两种方式（报告生成、命令行交互），还可以在浏览器里进行交互。先生成 profile 文件，再执行命令：
YEH！@LAPTOP-794D6PB5 MINGW64 /d/shixi/Documents/probe-server-profile $ go tool pprof -http=:8080 ./profile 进入一个可视化操作界面：
点击菜单栏可以在：Top/Graph/Peek/Source 之间进行切换，甚至可以看到火焰图（Flame Graph）：
它和一般的火焰图相比刚好倒过来了，调用关系的展现是从上到下。形状越长，表示执行时间越长。</content></entry><entry><title>Golang三色标记+GC混合写屏障机制</title><url>https://yeplain.xyz/post/golang_gc/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>GC</tag></tags><content type="html">
Go语言的GC是一个值得探讨深究的问题，从V1.3的标记清除法到V1.5的三色标记法，再到V1.8并沿用至今的三色标记法+混合写屏障机制，它的发展过程十分有趣。那么具体是怎样实现的呢？一起和野生菌来看看吧~
Go v1.3 之前的标记清除法（mark and weep） GC ：Garbage Collection 垃圾回收
STW ：Stop the world &mdash;&ndash;>目的：减小这个时间
标记清除法流程 暂停程序业务逻辑，找出可达对象和不可达对象 开始标记，程序找出所有可达对象，并做上标记 标记完后，开始清除未标记的对象 停止暂停，程序继续运行，循环重复这个过程直到进程生命周期结束 标记清除法缺点 STW ：让程序暂停，程序出现卡顿（主要问题）
标记需要扫描整个heap
清除数据会产生heap碎片
解决办法 原有：
方法一：那么我们考虑将3、4互换位置？
先停止 再清除，使清除异步，减小STW的时间范围
但是标记的时间仍然很长
方法二： 尝试采用新的标记模式来替代标记清除法
即三色标记法
Go v1.5 三色标记法 三色标记法流程 三色标记法中，我们在GC中统计3个集合：白色标记表、灰色标记表、黑色标记表
程序起初创建，全部标记为白色，将所有对象放入白色集合中 这里我们将程序的根节点集合展开的形式
遍历Root Set(非递归形式，只遍历一次)，得到灰色节点 遍历灰色标记表，将可达的对象从白色标记为灰色；遍历后的灰色标记为黑色 重复上一步，直到灰色标记表中无任何对象
收集所有白色对象（垃圾）
循环多次，逐层将垃圾清除
三色标记如果不使用STW会存在问题吗？ 答案是会的，举一个例子：
此时对象1、4已遍历标记完成，2、7已加入灰色标记表中
可以看出，已经标记为灰色的对象2，有指针p指向白的的对象3
现在还没有扫描对象2
但这时，由于无STW的保护，可能并发会有黑色对象4引用到了对象3，即q指针指向了对象3
与此同时，对象2将指针p移除，这样对象3就被挂在了已经扫描完成的黑色对象4下
再继续正常执行算法逻辑，对象2、7标记为黑色，而对象3因为对象4已经不会再扫描了，被当作垃圾回收清除了
这是就发生了三色标记法最不希望发生的事，总结来说就是两个被同时满足的条件：
条件1. 一个白色对象被黑色对象引用
条件2. 灰色对象不再引用这个白色对象
这时就发生了对象丢失的现象！
那么怎么解决呢？很直接的方式就是继续利用我们之前的STW，但是它浪费了很多资源，对用户程序有很大的影响
那么如何在保证对象不丢失的情况下尽可能的提高GC效率，减少STW时间呢？
这就需要提出强弱三色不变式了
强弱三色不变式 强三色不变式 强制性的不允许黑色对象引用白色对象（破坏条件1）
弱三色不变式 黑色对象可以引用白色，但白色对象存在其他灰色对象对它引用，或者可达它的链路上游存在灰色（破坏条件2）
所以可以看出，只要满足强/弱之一，即可保证对象不丢失
那么如何实现呢？这里就用到了屏障机制
屏障机制 屏障：就是加入额外的判断机制，不打扰正常的业务
插入写屏障 对象被引用时，触发的机制
具体操作 在黑色A对象引用B对象时，B对象被标记为灰色（满足强三色不变式）
为了不影响性能，不在栈上使用
这里，对象8，9是黑色对象新引用的对象，但只将8标记为了灰色，对象9仍然是白色
在准备回收白色前，重新遍历扫描一次栈空间，此时加STW暂停保护栈，防止有新的白色被黑色引用
不足 结束时需要STW重新扫描栈，大约消耗10-100ms
删除写屏障 对象被删除时，触发的机制
具体操作 被删除的对象，如果自身为灰色或白色，那么被标记为灰色（满足弱三色不变式）
但可能出现问题，如图中对象5未被删除
不足 回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以存活过这一轮，在下一轮GC中被清理掉
Go v1.8混合写屏障机制 之前我们可以看到插入写屏障和删除写屏障都有一些不足
因此提出了混合写屏障机制
满足：变形的弱三色不变式
流程 GC开始将栈上的对象全部扫描并标记为黑色（之后不再进行二次扫描，无需STW） GC期间，任何在栈上创建的新对象，均为黑色 被删除的对象标记为灰色 被添加的对象标记为灰色 真实场景 场景一：对象被一个堆对象删除引用，成为另一个栈对象的下游
场景二：对象被一个栈对象删除引用，成为另一个栈对象的下游
场景三：对象被一个堆对象删除引用，成为另一个堆对象的下游
场景四：对象被一个栈对象删除引用，成为另一个堆对象的下游</content></entry><entry><title>在Probe-server部署Prometheus监控</title><url>https://yeplain.xyz/post/prometheus/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>Prometheus</tag></tags><content type="html">
由于实习工作需求，需要我对Probe-server部署普罗米修斯监控，从而动态观测其相应指标的统计变化，最后我分别使用gauge和counter数据类型对总访问次数、正常访问次数、正常返回次数、TCP各个方法调用次数、在线网关数进行监控，并连接grafana得到了友好的可视化输出！
介绍 Prometheus中文发音为普罗米修斯，它可以使用各种数学算法实现强大的监控需求，并且原生支持K8S的服务发现，能监控容器的动态变化。结合Grafana绘出漂亮图形，最终使用alertmanager或Grafana实现报警。它与其他监控相比有以下主要优势：数据格式是Key/Value形式，简单、速度快；监控数据的精细程度是绝对的领先，达到秒级（但正因为数据采集精度高，对磁盘消耗大，存在性能瓶颈，而且不支持集群，但可以通过联邦能力进行扩展）；不依赖分布式存储，数据直接保存在本地，可以不需要额外的数据库配置。但是如果对历史数据有较高要求，可以结合OpenTSDB；周边插件丰富，如果对监控要求不是特别严格的话，默认的几个成品插件已经足够使用；本身基于数学计算模型，有大量的函数可用，可以实现很复杂的监控（所以学习成本高，需要有一定数学思维，独有的数学命令行很难入门）；可以嵌入很多开源工具的内部去进行监控，数据更可信。
结构图如下：
Prometheus的主要组件 1. 服务端 Prometheus服务端以一个进程方式启动，如果不考虑参数和后台运行的话，只需要解压安装包之后运行./prometheus脚本即可启动，程序默认监听在9090端口。每次采集到的数据叫做metrics。这些采集到的数据会先存放在内存中，然后定期再写入硬盘，如果服务重新启动的话会将硬盘数据写回到内存中，所以对内存有一定消耗。Prometheus不需要重视历史数据，所以默认只会保留15天的数据。
2. 客户端 Prometheus客户端分为pull和push两种方式。如果是pull形式的话则是服务端主动向客户端拉取数据，这样需要客户端上安装exporters（导出器）作为守护进程，官网上也提供了很多exporters可以下载使用，比如使用最多的node_exporters，几乎把系统自身相关数据全部采集了，非常全面，node_exporter默认监听9100端口。
如果是push形式的话客户端需要安装pushgateway插件，然后运需要运维人员用脚本把监控数据组织成键值形式提交给pushgateway，再由它提交给服务端。它适合于现有exporters无法满足需求时，自己灵活定制。
总之：就是有两种方式: pushgateway和exporter。
exporter由Prometheus server 不断pull
pushgateway安装在服务端或客户端，我们把数据push到pushgateway，再由Prometheus server pull pushgateway
3. metrics主要数据类型 · Gauges：最简单、使用最多的指标，获取一个返回值，这个返回值没有变化规律，不能肯定它一定是增长或是减少的状态，采集回来是多少就是多少。比如硬盘容量、CPU内存使用率都适合使用Gauges数据类型。
· Counters：计数器。数据从0开始累计，理想状态下应该是永远增长或者是不变。适合统计机器开机时间、HTTP访问量
· Histograms：和summary一样属于高级指标，用于统计数据的分布情况。比如最小值、最大值、中间值。这个类型不太好理解，比如说统计一天的日志，大部分用户响应时间都是正常的，只有少量用户异常，如果这个时候取平均值的话，这少量用户的异常情况就会被掩盖过去，而Histograms可以分别统计出全部用户的响应时间，比如0-1秒的用户有多少、1-2秒的用户有多少（其实有点像Kibana）
具体到本项目，我使用Gauge对在线网关数进行了统计，其余使用Counter数据类型。
我的工作 首先新增了一个Prometheus_util.go文件，用于定义和初始化： package utils import ( "github.com/prometheus/client_golang/prometheus" "github.com/prometheus/client_golang/prometheus/collectors" "sinohorizon.com/probe-server/api/tcp-protocol/Protocol" tcp_protocol "sinohorizon.com/probe-server/api/tcp-protocol/Protocol" ) //统计在线网关数 var NumOnlineGateways = prometheus.NewGauge(prometheus.GaugeOpts{ Name: "online_gateways_numbers", Help: "The number of online gateways", }) //统计总访问次数 var NumTotalVisits = prometheus.NewCounter(prometheus.CounterOpts{ Name: "total_visits_numbers", Help: "The total number of visits", }) //统计正常访问次数 var NumSuccessVisits = prometheus.NewCounter(prometheus.CounterOpts{ Name: "success_visits_numbers", Help: "The success number of visits", }) //统计正常返回次数 var NumSuccessResponds = prometheus.NewCounter(prometheus.CounterOpts{ Name: "success_respond_numbers", Help: "The success number of responds", }) //统计HeartBeat调用次数 var NumHeartBeat = prometheus.NewCounter(prometheus.CounterOpts{ Name: "heartbeat_numbers", Help: "The number of heartbeat", }) //统计GetOnlineDeviceList次数 var NumGetOnlineDeviceList = prometheus.NewCounter(prometheus.CounterOpts{ Name: "GetOnlineDeviceList_numbers", Help: "The number of GetOnlineDeviceList", }) //统计GetDevicePort次数 var NumGetDevicePort = prometheus.NewCounter(prometheus.CounterOpts{ Name: "GetDevicePort_numbers", Help: "The number of GetDevicePort", }) //统计GetProbes次数 var NumGetProbes = prometheus.NewCounter(prometheus.CounterOpts{ Name: "GetProbes_numbers", Help: "The number of GetProbes", }) //统计GetUdpPayLoad次数 var NumGetUdpPayLoad = prometheus.NewCounter(prometheus.CounterOpts{ Name: "GetUdpPayLoad_numbers", Help: "The number of GetUdpPayLoad", }) //统计PingFailed次数 var NumPingFailed = prometheus.NewCounter(prometheus.CounterOpts{ Name: "PingFailed_numbers", Help: "The number of PingFailed", }) //统计MatchProbe次数 var NumMatchProbe = prometheus.NewCounter(prometheus.CounterOpts{ Name: "MatchProbe_numbers", Help: "The number of MatchProbe", }) //统计FinishGatewayScan次数 var NumFinishGatewayScan = prometheus.NewCounter(prometheus.CounterOpts{ Name: "FinishGatewayScan_numbers", Help: "The number of FinishGatewayScan", }) func InitMonitorRegister() (registry *prometheus.Registry) { // 创建一个自定义的注册表 registry = prometheus.NewRegistry() // 添加 process 和 Go 运行时指标到自定义的注册表中 registry.MustRegister(collectors.NewProcessCollector(collectors.ProcessCollectorOpts{})) registry.MustRegister(collectors.NewGoCollector()) //统计在线网关数 NumOnlineGateways.Set(0) registry.MustRegister(NumOnlineGateways) //统计总访问数 registry.MustRegister(NumTotalVisits) //统计成功访问次数 registry.MustRegister(NumSuccessVisits) //统计成功返回次数 registry.MustRegister(NumSuccessResponds) //统计各方法调用次数 registry.MustRegister(NumHeartBeat) registry.MustRegister(NumGetOnlineDeviceList) registry.MustRegister(NumGetDevicePort) registry.MustRegister(NumGetProbes) registry.MustRegister(NumGetUdpPayLoad) registry.MustRegister(NumPingFailed) registry.MustRegister(NumMatchProbe) registry.MustRegister(NumFinishGatewayScan) return } func IncMethodNums(bodyType Protocol.RequestBody) { if bodyType == tcp_protocol.RequestBodyHeartBeatRequest { NumHeartBeat.Inc() } else if bodyType == tcp_protocol.RequestBodyGetOnlineDevicesRequest { NumGetOnlineDeviceList.Inc() } else if bodyType == tcp_protocol.RequestBodyGetPortRequest { NumGetDevicePort.Inc() } else if bodyType == tcp_protocol.RequestBodyGetProbesRequest { NumGetProbes.Inc() } else if bodyType == tcp_protocol.RequestBodyGetUdpPayloadRequest { NumGetUdpPayLoad.Inc() } else if bodyType == tcp_protocol.RequestBodyPingFailedRequest { NumPingFailed.Inc() } else if bodyType == tcp_protocol.RequestBodyMatchProbesRequest { NumMatchProbe.Inc() } else if bodyType == tcp_protocol.RequestBodyFinishGatewayScanRequest { NumFinishGatewayScan.Inc() } } 接着在主函数application.go处增加
go func() { for { onlineGatewayNum := handler.GetOnlineGatewaysNum() utils.NumOnlineGateways.Set(float64(onlineGatewayNum)) time.Sleep(constants.UPDATE_ONELINE_GATEWAY_NUM_TIME) } }() go func() { http.Handle("/metrics", promhttp.HandlerFor(registry, promhttp.HandlerOpts{Registry: registry})) http.ListenAndServe(pprofListenStr, nil) }() 在各个方法入口处增加统计，如：
utils.NumTotalVisits.Inc() 最终可视化结果示例：
通过连接grafana，得到了非常Nice的可视化输出</content></entry><entry><title>k8s中grpc负载不均衡的问题探究</title><url>https://yeplain.xyz/post/grpc-http2/</url><categories><category>K8s</category></categories><tags><tag>grpc</tag><tag>HTTP2</tag><tag>k8s</tag></tags><content type="html">
在实习期间，公司流量平台的服务是基于gRPC微服务框架的，但是在使用K8s进行配置时，却发现出现了负载均衡失效的问题，那么是什么原因导致的，又该如何解决呢？一起和野生菌探究吧~
1. gRPC gRPC是由google开发的，是一款语言中立、平台中立、开源的RPC(Remote Procedure Call，远程过程调用)框架。
在gRPC里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，使得您能够更容易地创建分布式应用和服务。与许多 RPC框架类似，gRPC也是基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 gRPC 服务器来处理客户端调用。 特性 基于HTTP/2 HTTP/2 提供了连接多路复用、双向流、服务器推送、请求优先级、首部压缩等机制。可以节省带宽、降低TCP链接次数、节省CPU，帮助移动设备延长电池寿命等。gRPC 的协议设计上使用了HTTP2 现有的语义，请求和响应的数据使用HTTP Body 发送，其他的控制信息则用Header 表示。
IDL使用ProtoBuf gRPC使用ProtoBuf来定义服务，ProtoBuf是由Google开发的一种数据序列化协议（类似于XML、JSON、hessian）。ProtoBuf能够将数据进行序列化，并广泛应用在数据存储、通信协议等方面。压缩和传输效率高，语法简单，表达力强。
多语言支持 gRPC支持多种语言，并能够基于语言自动生成客户端和服务端功能库。目前已提供了C版本grpc、Java版本grpc-java 和 Go版本grpc-go，其它语言的版本正在积极开发中，其中，grpc支持C、C++、Node.js、Python、Ruby、Objective-C、PHP和C#等语言，grpc-java已经支持Android开发。
2. HTTP2.0 HTTP/2，也就是超文本传输协议第2版，不论是1还是2，HTTP的基本语义是不变的，比如方法语义（GET/PUST/PUT/DELETE），状态码（200/404/500等），Range Request，Cacheing，Authentication、URL路径， 不同的主要是下面几点：
多路复用 在 HTTP/1.1 协议中 「浏览器客户端在同一时间，针对同一域名下的请求有一定数量限制。超过限制数目的请求会被阻塞」。 HTTP/2 的多路复用(Multiplexing) 则允许同时通过单一的 HTTP/2 连接发起多重的请求-响应消息。
因此 HTTP/2 可以很容易的去实现多流并行而不用依赖建立多个 TCP 连接，HTTP/2 把 HTTP 协议通信的基本单位缩小为一个一个的帧，这些帧对应着逻辑流中的消息。并行地在同一个 TCP 连接上双向交换消息。 二进制帧 HTTP/2 传输的数据是二进制的。相比 HTTP/1.1 的纯文本数据，二进制数据一个显而易见的好处是：更小的传输体积。这就意味着更低的负载。二进制的帧也更易于解析而且不易出错，纯文本帧在解析的时候还要考虑处理空格、大小写、空行和换行等问题，而二进制帧就不存在这个问题。
头部压缩 HTTP是无状态协议。简而言之，这意味着每个请求必须要携带服务器需要的所有细节，而不是让服务器保存住之前请求的元数据。因为http2没有改变这个范式，所以它也需要这样（携带所有细节），因此 HTTP 请求的头部需要包含用于标识身份的数据比如 cookies，而这些数据的量也在随着时间增长。每一个请求的头部都包含这些大量的重复数据，无疑是一种很大的负担。对请求头部进行压缩，将会大大减轻这种负担，尤其对移动端来说，性能提高非常明显。
HTTP/2 使用的压缩方式是 HPACK。
HTTP2.0在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键-值对，对于相同的数据，不再通过每次请求和响应发送；通信期间几乎不会改变的通用键-值对（用户代理、可接受的媒体类型，等等）只需发送一次。
事实上,如果请求中不包含首部（例如对同一资源的轮询请求），那么首部开销就是零字节。此时所有首部都自动使用之前请求发送的首部。
如果首部发生变化了，那么只需要发送变化了数据在Headers帧里面，新增或修改的首部帧会被追加到“首部表”。首部表在 HTTP2.0的连接存续期内始终存在,由客户端和服务器共同渐进地更新。
添加请求优先级 为了方便流的传输顺序，每个流都有权重和依赖。每个流的权重值在1~256之间，每个流可以详细给出对其他流的依赖。权重和依赖的结合可以使客户端构建出优先级二叉树的形式，来表达出更想依次得到哪些响应，然后服务端可以按权重分配硬件资源。
服务器推送 服务端可以为每个客户端请求发送多个响应，也就是说，除了原始的响应，服务端还可以给客户端发送额外的资源。服务器推送的资源可以由客户端缓存，推送的资源可以在不同的页面上重复使用，推送的资源可以与其他资源一起复用，推送的资源可以由服务器决定优先级，推送的资源也可以被客户端拒绝。
3. 长连接与短连接 HTTP的长连接和短连接本质上是TCP长连接和短连接。HTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。 IP协议主要解决网络路由和寻址问题，TCP协议主要解决如何在IP层之上可靠地传递数据包，使得网络上接收端收到发送端所发出的所有包，并且顺序与发送顺序一致。TCP协议是可靠的、面向连接的。
短连接 HTTP1.0默认是短连接：也就是说每次与服务器交互，都需要新开一个连接。 连接->传输数据->关闭连接 比如HTTP是无状态的的短链接，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。 因为连接后接收了数据就断开了，所以每次数据接受处理不会有联系。 这也是HTTP协议无状态的原因之一。
长连接 连接->传输数据->保持连接 -> 传输数据-> …->直到一方关闭连接，多是客户端关闭连接。 长连接指建立SOCKET连接后不管是否使用都保持连接，但安全性较差。
在HTTP1.1中默认就使用持久化连接来解决：建立一次连接，多次请求均由这个连接完成。 HTTP2所有性能增强的核心在于新的二进制分帧层(不再以文本格式来传输了)，它定义了如何封装http消息并在客户端与服务器之间传输。HTTP2连接上传输的每个帧都关联到一个“流”。流是一个独立的，双向的帧序列可以通过一个HTTP2的连接在服务端与客户端之间不断的交换数据。
什么时候用长连接，短连接？ 1、长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况。每个TCP连接都需要三步握手， 这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都 不断开，次处理时直接发送数据包就OK了，不用建立TCP连接。例如：数据库的连接用长连接， 如果 用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。
2、像WEB网站的http服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源，而像WEB网 站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成 千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连接好。
4. k8s中gRPC负载均衡失效 Kubernetes 的默认负载平衡通常不能与 gRPC 一起使用，在不使用 LoadBalance service 的情况下，因为 HTTP/2 链接复用特性，导致客户端的所有请求都发往同一个 Pod，导致负载不均衡。
原因可见gRPC Load Balancing on Kubernetes without Tears
首先，让我们了解为什么我们需要为 gRPC 做一些特别的事情。
gRPC 是应用程序开发人员越来越普遍的选择。与 JSON-over-HTTP 等替代协议相比，gRPC 可以提供一些显着的好处，包括显着降低（反）序列化成本、自动类型检查、形式化 API 和更少的 TCP 管理开销。
但是，gRPC 也打破了标准的连接级负载平衡，包括 Kubernetes 提供的负载平衡。这是因为 gRPC 是建立在 HTTP/2 之上的，而 HTTP/2 旨在拥有一个TCP长连接，所有请求都通过该连接进行多路复用——这意味着多个请求可以在任何时间点在同一个连接上处于活动状态。通常，这很好，因为它减少了连接管理的开销。但是，这也意味着（如您所想）连接级别的平衡不是很有用。一旦建立连接，就无需再进行平衡了。所有请求都将固定到单个目标 pod，如下所示： 那么为什么对于HTTP/1.1没有影响呢？ HTTP/1.1 也有长连接的概念，之所以在 HTTP/1.1中没有出现这个问题，是因为 HTTP/1.1 有几个特性自然会导致 TCP 连接循环。正因为如此，连接级别的平衡“足够好”，对于大多数 HTTP/1.1 应用程序，我们不需要做更多的事情。
要了解原因，让我们更深入地了解 HTTP/1.1。与 HTTP/2 相比，HTTP/1.1 不能多路复用请求。每个 TCP 连接一次只能激活一个 HTTP 请求。客户端发出请求，例如GET /foo，然后等待服务器响应。当请求-响应周期发生时，不能在该连接上发出其他请求。
通常，我们希望大量请求并行发生。因此，为了有并发的 HTTP/1.1 请求，我们需要建立多个 HTTP/1.1 连接，并在所有这些连接上发出我们的请求。此外，长期 HTTP/1.1 连接通常会在一段时间后过期，并被客户端（或服务器）断开。这两个因素结合在一起意味着 HTTP/1.1 请求通常会在多个 TCP 连接之间循环，因此连接级别的平衡是有效的。
所以我们怎样实现gRPC的负载均衡(load balance)呢？ 现在回到 gRPC。由于我们无法在连接层面进行均衡，所以为了做 gRPC 负载均衡，我们需要从连接均衡转向request均衡。换句话说，我们需要为每个目标打开一个 HTTP/2 连接，并在这些连接之间平衡request，如下所示： 在网络方面，这意味着我们需要在 L5/L7 而不是 L3/L4 做出决策，即我们需要了解通过 TCP 连接发送的协议。
我们如何做到这一点？有几个选择。首先，我们的应用程序代码可以手动维护自己的目标负载平衡池，我们可以配置我们的 gRPC 客户端以使用这个负载平衡池。这种方法为我们提供了最大的控制权，但它在 Kubernetes 等环境中可能非常复杂，在 Kubernetes 重新调度 Pod 时，池会随着时间而变化。我们的应用程序必须观察 Kubernetes API 并与 Pod 保持同步。
或者，使用如下两种方法：
代理负载平衡 在代理负载均衡中，客户端将rpc发送给LB (load Balancer)代理。LB将RPC调用分发到一个可用的后端服务器，该后端服务器实现为调用提供服务的实际逻辑。LB跟踪每个后端的负载，并实现公平分配负载的算法。客户端本身并不知道后台服务器。客户端是不可信的。这种体系结构通常用于面向用户的服务，其中来自开放互联网的客户端可以连接到服务器。
客户端负载均衡 在客户端负载平衡中，客户端知道许多后端服务器，并为每个RPC选择一个后端服务器。如果客户端希望实现基于服务器负载报告的负载均衡算法。对于简单的部署，客户机可以在可用的服务器之间轮询请求。
我们考虑使用 gRPC client LB 配合 Headless Service
使用gRPC client LB 配合 Headless Service在 Kubernetes 上实现 gRPC 负载平衡 ···· 未完待续····</content></entry><entry><title>高危端口及解决方案</title><url>https://yeplain.xyz/post/port/</url><categories><category>cybersecurity</category></categories><tags><tag>port</tag><tag>cybersecurity</tag></tags><content type="html"> 介绍135、139、445三个高危端口，以及它们的关闭和开启方式。
135端口 端口介绍 在 Windows 默认的五个典型开放端口中，135 用途最为复杂，也最容易引起外部攻击。主要用于使用RPC（远程过程调用）协议并提供DCOM（分布式组件对象模型）服务。
通过RPC可以保证在一台计算机上运行的程序可以顺利地执行远程计算机上的代码：具体来说，会向对方电脑的 135 端口询问可以使用哪个端口进行通信。这样，对方的电脑就会告知可以使用的端口号。使用DCOM可以通过网络直接进行通信，能够包括HTTP协议在内的多种网络传输。
端口漏洞 Windows 2000和Windows XP⽤户曾中的“冲击波”病毒就是利⽤RPC漏洞进行攻击。RPC本⾝在处理通过TCP/IP的消息交换部分有⼀个漏洞，该漏洞是由于错误地处理格式不正确的消息造成的。该漏洞会影响到RPC与DCOM之间的⼀个接⼝，该接⼝侦听的端⼝就是135。
操作建议 为了避免“冲击波”病毒的攻击，建议关闭该端⼝。
关闭方法 单击 “开始”-“运行”，输入 “dcomcnfg”，单击 “确定”，打开组件服务。 在弹出的 “组件服务” 对话框中，选择 “计算机” 选项。 在 “计算机” 选项右边，右键单击 “我的电脑”，选择 “属性”。 在出现的 “我的电脑属性” 对话框 “默认属性” 选项卡中，去掉 “在此计算机上启用分布式 COM” 前的勾。 选择 “默认协议” 选项卡，选中 “面向连接的 TCP/IP”，单击 “移除” 按钮。 单击 “确定” 按钮，设置完成，重新启动后即可关闭 135 端口。 开启方法 单击 “开始”-“运行”，输入 “dcomcnfg”，单击 “确定”，打开组件服务。 在弹出的 “组件服务” 对话框中，选择 “计算机” 选项。 在 “计算机” 选项右边，右键单击 “我的电脑”，选择 “属性”。 在出现的 “我的电脑属性” 对话框 “默认属性” 选项卡中，选中 “在此计算机上启用分布式 COM” 前的勾。 选择 “默认协议” 选项卡，单击“添加”按钮，选中 “面向连接的 TCP/IP”。 单击 “确定” 按钮，设置完成，重新启动后即可打开 135 端口。 139端口 端口介绍 139端口用于NBT协议（即Net Bios Over TCP/IP），其属于SMB（Server Message Block）Windows协议族。NBT使用137（UDP）、138（UDP）和139（TCP）来实现基于TCP/IP的NETBIOS网际互联。而139端口的作用就是获得NETBIOS/SMB服务（即NetBIOS File and Print Sharing协议），这个协议被用于Windows文件和打印机共享。
具体来说，SMB协议根据 DNS 服务器中的名字列表信息，寻找需要通信的对象。如果顺利地得到对象的 IP 地址，就可以访问共享资源 。Windows 2000 以前版本的 Windows 使用 NetBIOS 协议解决各计算机名的问题。通过向 WINS 服务器发送通信对象的 NetBIOS 名，取得 IP 地址。
在 SMB 通信中，首先要取得通信对象的 IP 地址，然后向通信对象发出开始通信的请求。如果对方充许进行通信，就会确立会话层(Session)。并使用它向对方发送用户名和密码信息，进行认证。如果认证成功，就可以访问对方的共享文件。在这些一连串的通信中使用的就是 139 端口。
端口漏洞 在默认设置下，Windows 会开放提供文件共享服务的 TCP 139 号端口。一旦文件共享服务启动，系统就会进入等待状态。而共享资源则可以利用 net 命令轻松地进行分配。尽管 C 盘如果没有管理员权限就无法共享，但如果不经意地将 Guest 帐号设置为有效以后，攻击者就能够访问 C 盘，非常轻松地破坏硬盘。 2017年10月，由于病毒“坏兔子”来袭，国家互联网应急中心等安全机构建议用户及时关闭计算机以及网络设备上的445和139端口。
操作建议 在因特网上公开的服务器打开 139 端口是一件非常危险的事情。如果有 Guest 帐号，而且没有设置任何密码时，就能够被人通过因特网轻松地盗看文件。如果给该帐号设置了写入权限，甚至可以轻松地篡改文件。也就是说在对外部公开的服务器中不应该打开这些端口。通过因特网使用文件服务器就等同自杀行为，因此一定要关闭 139 端口。
关闭方法 打开控制面板，选择“网络和Internet”。 在弹出的 “网络和Internet” 对话框中，单击 “网络和共享中心” 按钮。 在出现的 “网络和共享中心” 对话框中，选择左侧 “更改适配器设置”。 然后选中本地连接的网络，右键“属性”。 选择Internet协议版本4（TCP/IPv4）—>属性—>高级—>WINS—>禁用TCP/IP上的NetBIOS(S)。 单击 “确定” 按钮，设置完成，重新启动后即可关闭 135 端口。 开启方法 打开控制面板，选择“网络和Internet”。 在弹出的 “网络和Internet” 对话框中，单击 “网络和共享中心” 按钮。 在出现的 “网络和共享中心” 对话框中，选择左侧 “更改适配器设置”。 然后选中本地连接的网络，右键“属性”。 选择Internet协议版本4（TCP/IPv4）—>属性—>高级—>WINS—>启用TCP/IP上的NetBIOS(S)。 单击 “确定” 按钮，设置完成，重新启动后即可打开 135 端口。 445端口 端口介绍 445 端口是一种TCP端口，该端口在windows 2000 Server或Windows Server 2003系统中发挥的作用与139 端口是完全相同的。具体地说，它可以提供局域网中文件或打印机共享服务。不过该端口是基于CIFS协议（通用因特网文件系统协议）工作的，而139 端口是基于SMB协议（服务器协议族）对外提供共享服务。同样地，攻击者与445 端口建立请求连接，也能获得指定局域网内的各种共享信息。
445 端口的作用是实现一些共享文件夹以及一些共享打印机的访问工作，只要在局域网络的范围之内就能进行轻松的访问工作。
端口漏洞 由于只要在局域网络的范围之内就能通过445 端口进行访问，所以黑客侵入的可能性很高，黑客可以通过445端口进入我们的硬盘，从而对我们的文件进行共享，或者将我们硬盘内的数据格式化，导致我们的数据丢失。 2017年10月，由于病毒“坏兔子”来袭，国家互联网应急中心等安全机构建议用户及时关闭计算机以及网络设备上的445和139端口。多家网络安全机构监测分析发现，与此前席卷多国的WannaCry、Petya勒索病毒类似，这次在集团范围内传播的“蠕虫”病毒也会以感染的设备为跳板，攻击局域网内的其他电脑，形成“一台中招，一片遭殃”的情况。
操作建议 与139 端口类似，公开服务器 445 端口是一件非常危险的事情。容易被黑客通过因特网轻松地盗看文件。如果给该帐号设置了写入权限，甚至可以轻松地篡改文件。也就是说在对外部公开的服务器中不应该打开这些端口。通过因特网使用文件服务器就等同自杀行为，因此建议关闭445 端口。
关闭方法 单击 “开始”-“运行”，输入 “regedit”，单击 “确定” 按钮，打开注册表。 找到注册表项 “HKEY_LOCAL_MACHINE\System\Controlset\Services\NetBT\Parameters”。 选择 “Parameters” 项，右键单击，选择 “新建”——“DWORD 值”。 将 DWORD 值命名为 “SMBDeviceEnabled”。 右键单击 “SMBDeviceEnabled” 值，选择 “修改”。 在出现的 “编辑 DWORD 值” 对话框中，在 “数值数据” 下，输入 “0”，单击 “确定” 按钮，完成设置。 开启方法 单击 “开始”-“运行”，输入 “regedit”，单击 “确定” 按钮，打开注册表。 找到注册表项 “HKEY_LOCAL_MACHINE\System\Controlset\Services\NetBT\Parameters”。 选择 “Parameters” 项。 在右侧右键选中删除“SMBDeviceEnabled”值。 单击 “是” 按钮，设置完成，重新启动后即可打开 135 端口。</content></entry><entry><title>wsl2更新源失败问题</title><url>https://yeplain.xyz/post/wsl2/</url><categories><category>Linux</category></categories><tags><tag>wls</tag><tag>Linux</tag></tags><content type="html">
在使用wsl2时，由于其内部环境无法使用外部代理，因此需要更换源来加快下载或更新速度，但是换了多个源都出现了失败的问题，最后终于成功解决了，记录一下。
一般都会推荐使用国内的镜像源，比如163或者阿里云的镜像服务器
但是执行sudo apt-get update仍然报错，问题在于DNS没有配置好。 解决方法：
sudo vi /etc/resolv.conf
添加
# Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)# DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTENnameserver 127.0.1.1#这里用的是阿里云的DNS服务器nameserver 223.5.5.5 nameserver 223.6.6.6</content></entry><entry><title>Redis持久化实现方式</title><url>https://yeplain.xyz/post/redis-persist/</url><categories><category>Redis</category></categories><tags><tag>Redis</tag></tags><content type="html">
怎么样批量实现Redis中key的持久化？一起来看看吧~
方法一 编写shell脚本：使用管道
redis-cli -h 127.0.0.1 -p 6379 keys "white:*" | xargs -i redis-cli -h 127.0.0.1 -p 6379 expire {} 86400 redis-cli keys "white:*" | xargs -i redis-cli expire {} 86400 redis-cli -h 127.0.0.1 -p 6379 keys "white:*" | xargs redis-cli -h 127.0.0.1 -p 6379 del 方法二 用Go写了一个脚本，buid为linux上的二进制文件后执行：
package main import ( "fmt" "github.com/garyburd/redigo/redis" ) func main() { conn, err := redis.Dial("tcp", "127.0.0.1:6379") if err != nil { fmt.Println("Connect redis failed,", err) return } defer conn.Close() persist("rls:*", conn) persist("white:*", conn) persist("black:*", conn) persist("grey:*", conn) persist("breach:white*", conn) persist("breach:black*", conn) } func persist(Key string, conn redis.Conn) { scan, err := conn.Do("Scan", "0", "match", Key, "count", 2000000) if err != nil { fmt.Println("connect redis failed,", err) return } dataList := scan.([]interface{})[1].([]interface{}) for _, item := range dataList { itemStr := string(item.([]uint8)) _, err = conn.Do("PERSIST", itemStr) if err != nil { fmt.Println(err) return } } fmt.Printf("%s PERSIST done!\n", Key) return }</content></entry><entry><title>Redis与Mysql一致性实现探究</title><url>https://yeplain.xyz/post/redis-mysql/</url><categories><category>Redis</category></categories><tags><tag>Redis</tag><tag>Mysql</tag></tags><content type="html">
在实习的项目开发中，遇到了一个问题，就是流量平台的数据都存储在数据库中，缓存会存一部分，但由于有TTL，会定期删除，因此如何保证Redis和Mysql中的数据一致性是个亟待解决的问题。一起来看看吧~
具体来说：
如果只是将redis的TTL=-1，可能会导致问题： a. 缓存利用率低：不经常访问的数据，还一直留在缓存中
b. 数据不一致：因为是「定时」刷新缓存，缓存和数据库存在不一致（取决于定时任务的执行频率）
并发中，我们考虑同步对二者内部的数据进行修改，有两种方案： ​ a. 先更新缓存，后更新数据库
​ b. 先更新数据库，后更新缓存
​ a的话，若后者失败，则前者失效后，再读则会重置旧值
​ b的话， 若后者失败，要一段时间后才会更新
并发的时候，会出现不一致的问题，添加分布式锁可以解决，但每次数据发生变更，都「无脑」更新缓存，但是缓存中的数据不一定会被「马上读取」，这就会导致缓存中可能存放了很多不常访问的数据，浪费缓存资源。这种「更新数据库 + 更新缓存」的方案，不仅缓存利用率不高，还会造成机器性能的浪费。
因此，使用删除缓存的解决办法： ​ a. 先删除缓存，后更新数据库
b. 先更新数据库，后删除缓存
a并发的时候，还是有不一致的情况发生; b由于更新数据库（写）的时间比读的时间长, 且会加锁，发生问题概率低
如果后者失败，则多次重试： 立即重试很大概率「还会失败」
「重试次数」设置多少才合理？
重试会一直「占用」这个线程资源，无法服务其它客户端请求
因此要异步重试：把重试请求写到「消息队列」中，然后由专门的消费者来重试，直到成功。
或者更直接的做法，为了避免第二步执行失败，我们可以把操作缓存这一步，直接放到消息队列中，由消费者来操作缓存。
消息队列保证可靠性：写到队列中的消息，成功消费之前不会丢失（重启项目也不担心）
消息队列保证消息成功投递：下游从队列拉取消息，成功消费后才会删除消息，否则还会继续投递消息给消费者（符合我们重试的需求）
如果确实不想在应用中去写消息队列，近几年比较流行的解决方案：订阅数据库变更日志，再操作缓存。 具体来讲就是业务应用在修改数据时，「只需」修改数据库，无需操作缓存。MySQL 举例，当一条数据发生修改时，MySQL 就会产生一条变更日志（Binlog），我们可以订阅这个日志，拿到具体操作的数据，然后再根据这条数据，去删除对应的缓存。
订阅变更日志，目前也有了比较成熟的开源中间件，例如阿里的 canal，使用这种方案的优点在于：
无需考虑写消息队列失败情况：只要写 MySQL 成功，Binlog 肯定会有
自动投递到下游队列：canal 自动把数据库变更日志「投递」给下游的消息队列
至此，我们可以得出结论，想要保证数据库和缓存一致性，推荐采用「先更新数据库，再删除缓存」方案，并配合「消息队列」或「订阅变更日志」的方式来做。
如果使用「先更新数据库，再删除缓存」方案，其实也发生不一致：
线程 A 更新主库 X = 2（原值 X = 1）
线程 A 删除缓存
线程 B 查询缓存，没有命中，查询「从库」得到旧值（从库 X = 1）
从库「同步」完成（主从库 X = 2）
线程 B 将「旧值」写入缓存（X = 1）
最终 X 的值在缓存中是 1（旧值），在主从库中是 2（新值），也发生不一致。
缓存延迟双删策略： 线程 A 可以生成一条「延时消息」，写到消息队列中，消费者延时「删除」缓存。
双删的策略就是保证每次在数据修改的时候去吧redis 的数据删完 然后让它去查数据库</content></entry><entry><title>详解Redis缓存穿透、击穿、雪崩原理及解决方法</title><url>https://yeplain.xyz/post/my-first-post/</url><categories><category>Redis</category></categories><tags><tag>Redis</tag></tags><content type="html">
在实际的项目开发中，用户的数据我们一般都使用数据库进行存储，其数据是存储在磁盘上的，虽然稳定，但I/O速度很慢，当用户量很多且有并发需求时，请求数量一上来数据库就很容易崩溃。
为了解决这一问题，Redis这一内存数据库得到了广泛的应用，将其作为缓存中间件，可以将磁盘数据库中的数据缓存在Redis上，从而相当于在内存上进行了缓存，可以大大提高读写速度，提高系统性能。
然而在缓存中，由于Redis和Mysql这类磁盘数据库速度的不匹配，会出现缓存异常的问题，其中缓存穿透、缓存击穿、缓存雪崩是需要考虑并解决的问题。
缓存穿透 问题描述 Key对应的数据并不存在，每次请求访问key时，缓存中查找不到，请求都会直接访问到数据库中去，请求量超出数据库时，便会导致数据库崩溃。如一个用户id不存在，数据库与缓存都不存在该id，此时黑客便可以利用此漏洞不断访问该id，造成数据库崩溃。
解决方案 ①对空值缓存：如果一个查询数据为空（不管数据是否存在），都对该空结果进行缓存，其过期时间会设置非常短。
②设置可以访问名单：使用bitmaps类型定义一个可以访问名单，名单id作为bitmaps的偏移量，每次访问时与bitmaps中的id进行比较，如果访问id不在bitmaps中，则进行拦截，不给其访问。
③采用布隆过滤器：布隆过滤器可以判断元素是否存在集合中，他的优点是空间效率和查询时间都比一般算法快，缺点是有一定的误识别率和删除困难。
④进行实时监控：对于redis缓存中命中率急速下降时，迅速排查访问对象和访问数据，将其设置为黑名单。
缓存击穿 问题描述 key中对应数据存在，当key中对应的数据在缓存中过期，而此时又有大量请求访问该数据，缓存中过期了，请求会直接访问数据库并回设到缓存中，高并发访问数据库会导致数据库崩溃。
解决方案 ①预先设置热门数据：在redis高峰访问时期，提前设置热门数据到缓存中，或适当延长缓存中key过期时间。
②实时调整：实时监控哪些数据热门，实时调整key过期时间。
③对于热点key设置永不过期。
缓存雪崩 问题描述 key中对应数据存在，在某一时刻，缓存中大量key过期，而此时大量高并发请求访问，会直接访问后端数据库，导致数据库崩溃。 注意：缓存击穿是指一个key对应缓存数据过期，缓存雪崩是大部分key对应缓存数据过期
解决方案 ①构建多级缓存机制：nginx缓存+redis缓存+其他缓存。
②设置过期标志更新缓存：记录缓存数据是否过期，如果过期会触发另外一个线程去在后台更新实时key的缓存。
③将缓存可以时间分散：如在原有缓存时间基础上增加一个随机值，这个值可以在1-5分钟随机，这样过期时间重复率就会降低，防止大量key同时过期。
④使用锁或队列机制：使用锁或队列保证不会有大量线程一次性对数据库进行读写，从而避免大量并发请求访问数据库，该方法不适用于高并发情况。</content></entry><entry><title>Linux及shell相关指令学习笔记</title><url>https://yeplain.xyz/post/shell/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>Shell</tag></tags><content type="html">
Linux及Shell常用指令学习笔记~
Linux ctrl + alt + f1~f6 进入真正shell终端控制台
ctrl + alt + f7 图形化界面
ctrl + / ctl - 放大缩小
ls pwd
linux 只有一棵树
cd / 切换到根目录
根目录下的文件夹说明 /bin : 存放可以直接执行的常用命令 （链接到/usr/bin/)
/sbin : 管理员用的指令（链接到/usr/sbin/)
/lib : 库目录，放置动态链接库（链接到/usr/lib/)
/lib64 : 64位特殊的动态链接库（链接到/usr/lib64/)
/boot : 存放内核及启动所需要的文件
/dev : 设备目录
/etc : 系统需要的配置文件 .conf
/home : 普通用户的主目录
/root : 管理员用户的主目录
/opt : 放置其他第三方文件
/media ：挂载目录，识别U盘、光驱等外部设备
/mnt : 挂载目录，外部存储
/proc：进程目录
/run : 运行时的临时信息，重启后无
/srv : 系统服务
/sys : 系统硬件信息
/tmp : 系统临时目录
/usr : 用户相关的文件
/var : 放置log日志等文件
Vi/ Vim编辑器 vim 编辑器之神(小而精) emacs 神之编辑器(all in one)
切换输入法 win + 空格
vim ... vi ...
三种模式：
命令模式下： w //已写入 q //退出
一般模式 u //撤回 yy//复制一行 p//粘贴 5p//粘贴5行 8yy//复制了8行
dd //删除当前行 3dd //删除3行 dw //删除当前词 d$//删除当前光标后这一行的内容 d^ //删除当前光标前的内容
y$ //复制当前光标后这一行的内容 y^ //复制当前光标前的内容 yw//复制当前光标单词
x //光标所在位置之后一个个剪切 X//光标所在位置之前一个个剪切
r // 替换当前字符 R //替换一串字符，会依次替换
^ //移动到行头 $ //移动到行尾 w //移动到下一个词头
b //上一个词词头 e//移动到当前词尾
gg //文档开头 G//文档最后一行 3G //跳到第3行行头
命令模式下 set nu //显示行号 set nonu //关闭行号
编辑模式 命令模式 网络配置和系统管理操作 ifconfig //查看网络配置
ping //icmp
桥接模式 NAT模式
vim /etc/sysconfig/net/network-scripst/ifcfg-ens33
service network restart //重启网络服务
hostname //显示主机名
vim /etc/hostname //修改主机名
ssh root@主机名 //ssh远程登陆 Xshell为主要工具
系统管理 Linux服务管理 service 服务：启动后一直存在，常驻内存的进程
守护进程daemon = 系统服务
service 服务名 start | stop |restart |status
查看服务的方法：
ls /usr/lib/systemd/
新： systemctl status network
系统运行级别 setup设置自启动服务
开机 -> BIOS -> /boot ->init进程 -》运行级别 -》运行级别对应的服务
关机重启 shutdown
shutdown -c // 取消
shutdown now //立即关机
shutdown 3 //3min后关机
shutdown 15:28 // 定时关机
sync //将数据由内存同步到硬盘中
halt //停机，关闭系统，但不断电
poweroff //断电
reboot //重启 == shutdown -r now
经验： 先sync 再shutdown now
帮助命令 man ls
ctrl + l ->清屏
文件目录 基础 pwd //绝对路径
cd
cd ../ 返回上一层
cd - 返回上次的目录
ls
ls -a 所有 .开头的文件是隐藏文件
ls -l == ll
mkdir 创建目录
mkdir -p g/h/i 没有父目录就自动创建
rmdir 删除目录
touch a.txt 创建文件
cp source dest 复制文件到&hellip;
rm 删除文件
rm -f 强制删除
rm -r 递归删除
rm -rf 全部删除
rm -f ./* 删除当前目录下所有文件
mv source dest 移动文件
mv a.txt b.txt 重命名
cat 查看文件内容
cat -n 显示行号
more 按页显示文件内容 空格翻页 q退出
less 打开大的文件 b往前 /关键字 查询 q退出
echo 输出内容到控制台
echo -e 支持转义字符
####　输出重定向
ls -l > 文件 将列表内容写入文件(覆盖写)
ls -l &raquo; 文件 将列表内容追加写入文件末尾(追加写)
head -n 20 &hellip;txt 显示开头20行
tail -n 20 &hellip;txt 显示末尾20行
tail -f 文件 实时追踪文档所有更新
硬链接和软链接 Linux 链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。默认情况下，ln 命令产生硬链接。
硬连接
硬连接指通过索引节点来进行连接。在 Linux 的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在 Linux 中，多个文件名指向同一索引节点是存在的。比如：A 是 B 的硬链接（A 和 B 都是文件名），则 A 的目录项中的 inode 节点号与 B 的目录项中的 inode 节点号相同，即一个 inode 节点对应两个不同的文件名，两个文件名指向同一个文件，A 和 B 对文件系统来说是完全平等的。删除其中任何一个都不会影响另外一个的访问。
硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。
软连接
另外一种连接称之为符号连接（Symbolic Link），也叫软连接。软链接文件有类似于 Windows 的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。比如：A 是 B 的软链接（A 和 B 都是文件名），A 的目录项中的 inode 节点号与 B 的目录项中的 inode 节点号不相同，A 和 B 指向的是两个不同的 inode，继而指向两块不同的数据块。但是 A 的数据块中存放的只是 B 的路径名（可以根据这个找到 B 的目录项）。A 和 B 之间是“主从”关系，如果 B 被删除了，A 仍然存在（因为两个是不同的文件），但指向的是一个无效的链接。
ln -s [原文件或目录] [软链接名] 在当前目录下给源文件创建一个软链接
相当于一个指针
pwd 显示该软链接的路径
pwd -P 显示所指的实际真正的物理路径
rm -rf myFolder 只是删除软链接
rm -rf myFolder/ 删除了真正的文件夹
ln [原文件或目录] [软链接名] 在当前目录下给源文件创建一个硬链接
通过上面的测试可以看出：当删除原始文件 f1 后，硬连接 f2 不受影响，但是符号连接 f3 文件无效
此外,硬链接只能针对文件,不能针对目录; 而软链接既可以文件也可以目录
其他 history 显示历史输入过的命令
history -c 清除历史
时间日期 date 当前时间信息
date + %Y
date + %m
date + %d
date &ldquo;+%Y-%m-%d %H:%M:%S&rdquo;
date +%s 当前秒数对应的时间戳(1970年1月1日到当前的秒数)
date -s &ldquo;2017-06-19 20:42:33&rdquo; 设置系统时间
ntpdate 同步时间
cal 当前月历
用户权限 用户 useradd 用户名 添加用户
cd /home 除了root, 添加的用户都在/home下
passwd 用户名 设置密码
id 用户名 看用户是否存在
cat /etc/passwd 查看所有用户
su 用户名 切换用户
who am i 当前用户名称
sudo 为普通用户赋予root权限
userdel 删除用户
用户组 groupadd 组名 新增组
usermod -g 组名 用户名 新增用户到组
groupdel 组名 删除组
文件权限 ll 或 ls -l 显示文件权限
改变文件权限:
chmod [{ugoa}{+-=}{rwx}] 文件或目录 (u:所有者 g:所有组 o:其他人)
chmod [mode=421] [文件或目录]
r =4 w=2 x=1 mode=[0,7]
eg: chmod 777 a.txt chmod 644 b.txt
chown 更改属主 -R(对文件夹,递归所有文件)
chgrp 更改属组
搜索查找 find [搜索范围] [选项] 对象
选项有 -name -user -size
eg: find /root -name &ldquo;*.cfg&rdquo;
​ find /root -size +10M
locate 搜索文件 //基于数据库查询
可能不及时,所以要先 updatedb
which [命令]
eg: which ls which locate
grep过滤查找及"|&ldquo;管道符
管道符&rdquo;|", 表示将前一个命令的处理结果输出传递给后面的命令处理
grep 选项 查找内容 源文件 (选项 -n 显示匹配行及行号)
eg: ls | grep .cfg
wc 文件名 (输出:行数 词数 字节数)
eg: grep -n boot initial-setup-ks.cfg | wc
压缩解压 gzip/gunzip 只能压缩文件不能压缩目录; 不保留原来的文件; 同时多个文件会产生多个压缩包
zip /unzip 可以压缩文件夹
-d 指定压缩目录
tar [选项] &hellip;tar.gz 打包操作
-c 打包 -x解包 -z打包同时压缩
eg: tar -zcvf temp.tar.gz a.cfg b.txt 打包压缩
tar -zxvf temp.tar.gz -C /temp 解压
磁盘管理 tree ./ 当下所有的目录信息
du 所有目录\子文件夹等的大小(disk usage)
du -sh
df -h 查看当前磁盘空间
free -h 查看内存使用
lsblk 查看设备挂载情况
mount /umount 挂载/卸载
fdisk 分区
fdisk -l 查看磁盘分区详情
进程管理 前台显示的进程 后台常驻的进程(服务,守护进程)
ps 显示所有用户进程
ps aux ps -ef(可以看进程父子关系)
kill [选项] PID 终止进程
-9 强制关闭
killall 进程名 通杀
systemctl start [服务名] 又开启了服务
pstree 查看进程树
-p 显示pid
top 实时查看进程
-d 指定多少秒刷新 -p 指定查看某个进程 -i 不显示闲置\僵尸进程
ifconfig ping
netstat -anp | grep 进程号 查看该进程网络信息
netstat -nlp | grep 端口号 查看网络端口号占用情况
crontab 设置定时任务
crontab -l 查看已有定时任务
crontab -e 编辑定时任务
详情见 &hellip;&hellip;..
Shell 执行脚本 chmod +x ./test.sh
./test.sh
或者 sh hello.sh 或者 source hello.sh 或者 . hello.sh
区别: sh 或者bash 执行是开了一个子shell , 而source 和./ 是直接在当前shell执行
使用变量 env 查看全局环境变量
set 查看所有变量
your_name="yuanye"
echo $your_name
echo ${your_name}
readonly your_name //设定为只读变量
unset your_name //删除变量
g="hello, "$your_name" ! " //字符串拼接
echo ${#your_name} //获取字符串长度
echo ${your_name:1:2} //从第2个字符开始截取2个字符
echo `expr index "$your_name" a` //查找子字符的位置
# 注释
:&lt;&lt;EOF ····· EOF //多行注释
传递参数 echo &ldquo;Shell 传递参数实例！&rdquo;; echo &ldquo;执行的文件名：$0&rdquo;; echo &ldquo;第一个参数为：$1&rdquo;; echo &ldquo;第二个参数为：$2&rdquo;; echo &ldquo;第三个参数为：$3&rdquo;;
chmod +x test.sh ./test.sh 1 2 3 $# 变量数
$* 所有变量整体 $@ 所有变量形成一个数组
$? 最后一次的返回值
基本运算符 expr 是一款表达式计算工具，使用它能完成表达式的求值操作。
例如，两个数相加 注意使用的是反引号 ` 而不是单引号 '：
val=`expr 2 + 2`
echo "两数之和为 ：$val"
echo $(()) 或者 $[] 更简便的写法
eg: b=$[2+2]
条件判断 test $a=Hello
echo $? 0为真 1为假
[ $a = hello] 中间有空格
echo $?
整数比较:
[ 2 -lt 5 ] -lt 小于 -gt 大于 -eq 等于 -le小于等于 -ge大于等于
文件判断:
[ -r hello.sh ] 看是否有什么权限 -r -w -x
[ -e /home/a.txt ] 看文件是否存在
多条件判断:
&amp;&amp; 前一条命令成功执行才执行后一条 || 前一条命令执行失败后才执行后一条
类似 &hellip;.. ? a : b 真执行a,假执行b
eg: [ 3 -lt 5 ] &amp;&amp; echo ok || echo notok
流程控制 if 判断 if [ 条件判断式 ]; then
程序
fi
等同于
if [ 条件判断式 ]
then
程序
fi
函数 系统函数 命令替换 eg: filename="$1"_log_$(date +%s)
basename /root/scipts/a.txt &mdash;> a.txt 去掉最后一个/前面的所有内容
dirname /root/scripts/a.txt &mdash;>/root/scripts 获取前面的路径部分
自定义函数 funname[]
{
​ Action;
​ [return int;]
}
正则表达式 模糊匹配
grep sed awk 都支持正则表达式
^ 匹配一行的开头
eg : grep ^a
$ 匹配一行的结束
eg : grep t$
. 匹配任意字符
eg: grep r..t 中间有两个字符
*出现任意次
eg: grep ro*t o出现任意多次 ,匹配root rot rooooot rt等等
以什么开头什么结尾:
grep ^a.*bash$ 以a开头,以bash结尾
字符区间 []
grep r[a,b]t 匹配rat,rbt
文本处理工具 cut cut [选项参数] filename
eg: cut -d " " -f 1 cut.txt
cat /etc/passed | grep bash$ | cut -d &ldquo;:&rdquo; -f 1,6,7
echo $PATH | cut -d &ldquo;:&rdquo; -f 2-
切割获取的ip地址:
ifconfig ens33 | grep netmask | cut -d " " -f 10
awk 把文件逐行的读入,已空格为默认分隔符将每行切片
awk [选项参数] &lsquo;/pattern1/ {action1} /pattern2/{action2}&hellip;&rsquo; filename
eg:搜索passwd文件已root关键字开头的所有行,并输出该行的第7列
cat /etc/passwd | grep ^root | cut -d &ldquo;:&rdquo; -f 7
cat /etc/passwd | awk -F &ldquo;:&rdquo; &lsquo;/ ^root/ print{$7}&rsquo;</content></entry><entry><title>从Protobuf到gRPC</title><url>https://yeplain.xyz/post/gprc-protobuf/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>grpc</tag></tags><content type="html">
Protobuf 是Protocol Buffers的简称，它是Google公司开发的一种数据描述语言，用于描述一种轻便高效的结构化数据存储格式，并于2008年对外开源。Protobuf可以用于结构化数据串行化，或者说序列化。它的设计非常适用于在网络通讯中的数据载体，很适合做数据存储或 RPC 数据交换格式，它序列化出来的数据量少再加上以 K-V 的方式来存储数据，对消息的版本兼容性非常强，可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。开发者可以通过Protobuf附带的工具生成代码并实现将结构化数据序列化的功能。一起和野生菌来看看吧~
protobuf 实际是一套类似Json或者XML的数据传输格式和规范，用于不同应用或进程之间进行通信时使用。通信时所传递的信息是通过Protobuf定义的message数据结构进行打包，然后编译成二进制的码流再进行传输或者存储。
具体实现方式为：
*.proto* –protoc, protoc-gen-go-> *.pb.go* :
protoc &ndash;go_out=output_directory input_directory/file.proto
( protoc &ndash;go_out=plugins=grpc:. ./hi.proto )
protoc是protobuf文件（.proto）的编译器，借助它可以把.proto文件转译成各种编程语言对应的源码。
protoc-gen-go插件可以产生go相关代码， 除上述序列化和反序列化代码之外， 还增加了一些通信公共库。它是protobuf编译插件系列中的Go版本
gRPC: 高性能，开源通用RPC框架。所谓RPC(remote procedure call 远程过程调用)框架实际是提供了一套机制，使得应用程序之间可以进行通信，而且也遵从server/client模型。使用的时候客户端调用server端提供的接口就像是调用本地的函数一样。</content></entry><entry><title>如何用Hugo搭建自己的个人博客(GithubPages + Aliyun)</title><url>https://yeplain.xyz/post/hugo-blog-make/</url><categories><category>blog</category></categories><tags><tag>hugo</tag><tag>github</tag><tag>blog</tag></tags><content type="html"> 个人博客有许多开源的框架，基于Go语言的Hugo框架有着快速方便的特点，且支持Markdown语法，利用它来构建博客可以大大提高我们的效率。下面一起来看看怎么基于它构建出我们理想的个人博客，并将它托管至GitHub上吧！
1. 安装Hugo 野生菌使用的是Windows系统，所以安装过程中会基于Windows进行讲解，有关其他操作系统的安装方法可以参考官方文档
首先去官网下载hugo框架，hugo官网
下载完成后检查是否安装成功，输入:hugo version，若出现版本信息则表示安装成功。 2. 新建站点 这时候我们已经安装好了hugo框架，接下来进入我们想要放置网站文件的文件夹中，输入hugo new site blog， 再进入新创建的路径下cd blog
野生菌恭喜你！已经创建了自己的博客啦~
3. 为博客设置主题 Hugo 中你可以自己构建博客的主题或者使用网上已经有的一些主题。前人栽树，后人乘凉，在hugo主题官网
中找一个自己喜欢的主题吧！ 然后进入主题所在的目录：cd themes 克隆主题：git clone https://themes.gohugo.io/themes/hugo-theme-next/,这里野生菌的主题是NexT
然后在themes文件夹下会出现如下目录： 之后按照主题对应的要求，配置相关的文件。 配置完成后，输入hugo server -D，在浏览器中输入http://localhost:1313，就可以在本地可视化你的博客啦！
4. 使用Github进行托管 这时候虽然博客雏形已经有了，但只能是在本地查看，为了让别人也能通过网址访问，我们可以使用GitHub来对我们的博客进行免费托管。
在 GitHub 上创建一个仓库，不过仓库名有特殊要求。如果是个人账号，比如野生菌的 GitHub ID 是 yeplain，则仓库名是：yeplain.github.io 之后在你的 Hugo 网站目录下键入命令hugo -v生成网站的相应文件，存储在 public 目录下。
进入public目录下，并按照正常的git命令操作： cd public git init git add . git commit -m "first commit" git remote add origin https://github.com/yeplain/yeplain.github.io.git #推送到远程git git push origin master
之后如果我们写了新的博客 在blog文件夹中执行hugo 然后cd public 依次执行 git init git add . git commit -m "new commit" git push -u origin master 就行啦~~~
5. 使用Aliyun域名进行托管 首先在阿里云上购买一个域名，我买的是yeplain.xyz
通过实名认证后，选择对应域名中的解析
添加两条类型为CNAME的记录，值指向你自己的github博客url，我的是yeplain.github.io
在github博客仓库的Settings页面里，将腾讯云购买的域名指定到Custom domain里
然后就可以了！</content></entry><entry><title>Leetcode Study</title><url>https://yeplain.xyz/post/leetcode/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"> Leetcode 刷题之旅~
1. 数组中重复的数字 描述 在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组[2,3,1,0,2,5,3]，那么对应的输出是2或者3。存在不合法的输入的话输出-1
数据范围：0≤n≤10000
进阶：时间复杂度O(n) ，空间复杂度O(n)
示例 输入： [2,3,1,0,2,5,3] 返回值：2 说明：2或3都是对的
代码 func duplicate( numbers []int ) int { // write code here m := make(map[int]bool,len(numbers)) for _, num := range numbers{ if m[num] { return num }else{ m[num] = true } } return -1 } 2. 二维数组中的查找 描述 在一个二维数组array中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。
[
[1,2,8,9], [2,4,9,12], [4,7,10,13], [6,8,11,15]
]
给定 target = 7，返回 true。
给定 target = 3，返回 false。
示例 代码</content></entry><entry><title>操作系统系列：一、硬件结构(2)大话存储器的层次结构和如何写出更快的代码</title><url>https://yeplain.xyz/post/os12/</url><categories><category>basic</category></categories><tags><tag>basic</tag></tags><content type="html">
操作系统基本概念回顾笔记
存储器的层次结构 分如下几个级别：
寄存器； CPU Cache； L1-Cache； L2-Cache； L3-Cahce； 内存； SSD/HDD 硬盘 对于存储器，它的速度越快、能耗会越高、而且材料的成本也是越贵的，以至于速度快的存储器的容量都比较小。
寄存器 最靠近 CPU 的控制单元和逻辑计算单元的存储器，就是寄存器了，它使用的材料速度也是最快的，因此价格也是最贵的，那么数量不能很多。
存储器的数量通常在几十到几百之间，每个寄存器可以用来存储一定的字节（byte）的数据。比如：
32 位 CPU 中大多数寄存器可以存储 4 个字节； 64 位 CPU 中大多数寄存器可以存储 8 个字节。 寄存器的访问速度非常快，一般要求在半个 CPU 时钟周期内完成读写，CPU 时钟周期跟 CPU 主频息息相关，比如 2 GHz 主频的 CPU，那么它的时钟周期就是 1/2G，也就是 0.5ns（纳秒）。
CPU Cache CPU Cache 用的是一种叫 SRAM（*Static Random-Access* Memory，静态随机存储器） 的芯片。
SRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，而一旦断电，数据就会丢失了。
CPU 的高速缓存，通常可以分为 L1、L2、L3 这样的三层高速缓存，也称为一级缓存、二级缓存、三级缓存。
L1-Cache L1 高速缓存的访问速度几乎和寄存器一样快，通常只需要 2~4 个时钟周期，而大小在几十 KB 到几百 KB 不等。
每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以 L1 高速缓存通常分成指令缓存和数据缓存。
L2-Cache L2 高速缓存同样每个 CPU 核心都有，但是 L2 高速缓存位置比 L1 高速缓存距离 CPU 核心 更远，它大小比 L1 高速缓存更大，CPU 型号不同大小也就不同，通常大小在几百 KB 到几 MB 不等，访问速度则更慢，速度在 10~20 个时钟周期。
L3-Cache L3 高速缓存通常是多个 CPU 核心共用的，位置比 L2 高速缓存距离 CPU 核心 更远，大小也会更大些，通常大小在几 MB 到几十 MB 不等，具体值根据 CPU 型号而定。
访问速度相对也比较慢一些，访问速度在 20~60个时钟周期。
内存 内存用的芯片和 CPU Cache 有所不同，它使用的是一种叫作 DRAM （*Dynamic Random Access Memory*，动态随机存取存储器） 的芯片。
相比 SRAM，DRAM 的密度更高，功耗更低，有更大的容量，而且造价比 SRAM 芯片便宜很多。
DRAM 存储一个 bit 数据，只需要一个晶体管和一个电容就能存储，但是因为数据会被存储在电容里，电容会不断漏电，所以需要「定时刷新」电容，才能保证数据不会被丢失，这就是 DRAM 之所以被称为「动态」存储器的原因，只有不断刷新，数据才能被存储起来。
DRAM 的数据访问电路和刷新电路都比 SRAM 更复杂，所以访问的速度会更慢，内存速度大概在 200~300 个 时钟周期之间。
SSD/HDD硬盘 SSD（Solid-state disk） 就是我们常说的固体硬盘，结构和内存类似，但是它相比内存的优点是断电后数据还是存在的，而内存、寄存器、高速缓存断电后数据都会丢失。内存的读写速度比 SSD 大概快 10~1000 倍。
当然，还有一款传统的硬盘，也就是机械硬盘（Hard Disk Drive, HDD），它是通过物理读写的方式来访问数据的，因此它访问速度是非常慢的，它的速度比内存慢 10W 倍左右。
CPU Cache 的数据结构和读取过程是什么样的 CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的，而不是按照单个数组元素来读取数据的，在 CPU Cache 中的，这样一小块一小块的数据，称为 Cache Line（缓存块）。
比如，有一个 int array[100] 的数组，当载入 array[0] 时，由于这个数组元素的大小在内存只占 4 字节，不足 64 字节，CPU 就会顺序加载数组元素到 array[15]，意味着 array[0]~array[15] 数组元素都会被缓存在 CPU Cache 中了，因此当下次访问这些数组元素时，会直接从 CPU Cache 读取，而不用再从内存中读取，大大提高了 CPU 读取数据的性能。
事实上，CPU 读取数据的时候，无论数据是否存放到 Cache 中，CPU 都是先访问 Cache，只有当 Cache 中找不到数据时，才会去访问内存，并把内存中的数据读入到 Cache 中，CPU 再从 CPU Cache 读取数据。
这样的访问机制，跟我们使用「内存作为硬盘的缓存」的逻辑是一样的，如果内存有缓存的数据，则直接返回，否则要访问龟速一般的硬盘。
那 CPU 怎么知道要访问的内存数据，是否在 Cache 里？如果在的话，如何找到 Cache 对应的数据呢？我们从最简单、基础的直接映射 Cache（*Direct Mapped Cache*） 说起，来看看整个 CPU Cache 的数据结构和访问逻辑。
前面，我们提到 CPU 访问内存数据时，是一小块一小块数据读取的，具体这一小块数据的大小，取决于 coherency_line_size 的值，一般 64 字节。在内存中，这一块的数据我们称为内存块（*Block*），读取的时候我们要拿到数据所在内存块的地址。
对于直接映射 Cache 采用的策略，就是把内存块的地址始终「映射」在一个 CPU Line（缓存块） 的地址，至于映射关系实现方式，则是使用「取模运算」，取模运算的结果就是内存块地址对应的 CPU Line（缓存块） 的地址。
举个例子，内存共被划分为 32 个内存块，CPU Cache 共有 8 个 CPU Line，假设 CPU 想要访问第 15 号内存块，如果 15 号内存块中的数据已经缓存在 CPU Line 中的话，则是一定映射在 7 号 CPU Line 中，因为 15 % 8 的值是 7。
机智的你肯定发现了，使用取模方式映射的话，就会出现多个内存块对应同一个 CPU Line，比如上面的例子，除了 15 号内存块是映射在 7 号 CPU Line 中，还有 7 号、23 号、31 号内存块都是映射到 7 号 CPU Line 中。
因此，为了区别不同的内存块，在对应的 CPU Line 中我们还会存储一个组标记（Tag）。这个组标记会记录当前 CPU Line 中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。
除了组标记信息外，CPU Line 还有两个信息：
一个是，从内存加载过来的实际存放数据（*Data*）。 另一个是，有效位（*Valid bit*），它是用来标记对应的 CPU Line 中的数据是否是有效的，如果有效位是 0，无论 CPU Line 中是否有数据，CPU 都会直接访问内存，重新加载数据。 CPU 在从 CPU Cache 读取数据的时候，并不是读取 CPU Line 中的整个数据块，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个字（*Word*）。那怎么在对应的 CPU Line 中数据块中找到所需的字呢？答案是，需要一个偏移量（Offset）。
因此，一个内存的访问地址，包括组标记、CPU Line 索引、偏移量这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。而对于 CPU Cache 里的数据结构，则是由索引 + 有效位 + 组标记 + 数据块组成。
如果内存中的数据已经在 CPU Cahe 中了，那 CPU 访问一个内存地址的时候，会经历这 4 个步骤：
根据内存地址中索引信息，计算在 CPU Cahe 中的索引，也就是找出对应的 CPU Line 的地址； 找到对应 CPU Line 后，判断 CPU Line 中的有效位，确认 CPU Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行； 对比内存地址中组标记和 CPU Line 中的组标记，确认 CPU Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行； 根据内存地址中偏移量信息，从 CPU Line 的数据块中，读取对应的字。 到这里，相信你对直接映射 Cache 有了一定认识，但其实除了直接映射 Cache 之外，还有其他通过内存地址找到 CPU Cache 中的数据的策略，比如**全相连 Cache （Fully Associative Cache）、组相连 Cache （Set Associative Cache）**等.
如何写出让CPU执行更快的代码? 对于提升数据缓存命中率: ​ 遇到遍历数组的情况时，按照内存布局顺序访问
对于提升指令缓存命中率: 有一个元素为 0 到 100 之间随机数字组成的一维数组, 接下来，对这个数组做两个操作：
第一个操作，循环遍历数组，把小于 50 的数组元素置为 0； 第二个操作，将数组排序； 那么问题来了，你觉得先遍历再排序速度快，还是先排序再遍历速度快呢？
在回答这个问题之前，我们先了解 CPU 的分支预测器。对于 if 条件语句，意味着此时至少可以选择跳转到两段不同的指令执行，也就是 if 还是 else 中的指令。那么，如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快。
当数组中的元素是随机的，分支预测就无法有效工作，而当数组元素都是是顺序的，分支预测器会动态地根据历史命中数据对未来进行预测，这样命中率就会很高。
因此，先排序再遍历速度会更快，这是因为排序之后，数字是从小到大的，那么前几次循环命中 if &lt; 50 的次数会比较多，于是分支预测就会缓存 if 里的 array[i] = 0 指令到 Cache 中，后续 CPU 执行该指令就只需要从 Cache 读取就好了。
对于提升多核 CPU 的缓存命中率: 在单核 CPU，虽然只能执行一个线程，但是操作系统给每个线程分配了一个时间片，时间片用完了，就调度下一个线程，于是各个线程就按时间片交替地占用 CPU，从宏观上看起来各个线程同时在执行。
而现代 CPU 都是多核心的，线程可能在不同 CPU 核心来回切换执行，这对 CPU Cache 不是有利的，虽然 L3 Cache 是多核心之间共享的，但是 L1 和 L2 Cache 都是每个核心独有的，如果一个线程在不同核心来回切换，各个核心的缓存命中率就会受到影响，相反如果线程都在同一个核心上执行，那么其数据的 L1 和 L2 Cache 的缓存命中率可以得到有效提高，缓存命中率高就意味着 CPU 可以减少访问 内存的频率。
当有多个同时执行「计算密集型」的线程，为了防止因为切换到不同的核心，而导致缓存命中率下降的问题，我们可以把线程绑定在某一个 CPU 核心上，这样性能可以得到非常可观的提升。
总结 当 CPU 访问数据的时候，先是访问 CPU Cache，如果缓存命中的话，则直接返回数据，就不用每次都从内存读取速度了。因此，缓存命中率越高，代码的性能越好。
但需要注意的是，当 CPU 访问数据时，如果 CPU Cache 没有缓存该数据，则会从内存读取数据，但是并不是只读一个数据，而是一次性读取一块一块的数据存放到 CPU Cache 中，之后才会被 CPU 读取。
内存地址映射到 CPU Cache 地址里的策略有很多种，其中比较简单是直接映射 Cache，它巧妙的把内存地址拆分成「索引 + 组标记 + 偏移量」的方式，使得我们可以将很大的内存地址，映射到很小的 CPU Cache 地址里。
要想写出让 CPU 跑得更快的代码，就需要写出缓存命中率高的代码，CPU L1 Cache 分为数据缓存和指令缓存，因而需要分别提高它们的缓存命中率：
对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升； 对于指令缓存，有规律的条件分支语句能够让 CPU 的分支预测器发挥作用，进一步提高执行的效率； 另外，对于多核 CPU 系统，线程可能在不同 CPU 核心来回切换，这样各个核心的缓存命中率就会受到影响，于是要想提高线程的缓存命中率，可以考虑把线程绑定 CPU 到某一个 CPU 核心。</content></entry><entry><title>操作系统系列：一、硬件结构(1)CPU如何执行程序</title><url>https://yeplain.xyz/post/os11/</url><categories><category>basic</category></categories><tags><tag>basic</tag></tags><content type="html">
操作系统基本概念回顾笔记
CPU 是如何执行程序的 冯·诺依曼模型 在 1945 年冯·诺依曼和其他计算机科学家们提出了计算机具体实现的报告，其遵循了图灵机的设计，而且还提出用电子元件构造计算机，并约定了用二进制进行计算和存储。
最重要的是定义计算机基本结构为 5 个部分，分别是运算器、控制器、存储器、输入设备、输出设备，这 5 个部分也被称为冯诺依曼模型。
运算器、控制器是在中央处理器里的，存储器就我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘就是输入设备，显示器就是输出设备。
存储单元和输入输出设备要与中央处理器打交道的话，离不开总线。所以，它们之间的关系如下图：
接下来，分别介绍内存、中央处理器、总线、输入输出设备。
内存 我们的程序和数据都是存储在内存，存储的区域是线性的。
在计算机数据存储中，存储数据的基本单位是字节（*byte*），1 字节等于 8 位（8 bit）。每一个字节都对应一个内存地址。
内存的地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1，这种结构好似我们程序里的数组，所以内存的读写任何一个数据的速度都是一样的。
CPU 中央处理器也就是我们常说的 CPU，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据：
32 位 CPU 一次可以计算 4 个字节； 64 位 CPU 一次可以计算 8 个字节； 这里的 32 位和 64 位，通常称为 CPU 的位宽。
之所以 CPU 要这样设计，是为了能计算更大的数值，如果是 8 位的 CPU，那么一次只能计算 1 个字节 0~255 范围内的数值，这样就无法一次完成计算 10000 * 500 ，于是为了能一次计算大数的运算，CPU 需要支持多个 byte 一起计算，所以 CPU 位宽越大，可以计算的数值就越大，比如说 32 位 CPU 能计算的最大整数是 4294967295。
CPU 内部还有一些组件，常见的有寄存器、控制单元和逻辑运算单元等。其中，控制单元负责控制 CPU 工作，逻辑运算单元负责计算，而寄存器可以分为多种类，每种寄存器的功能又不尽相同。
CPU 中的寄存器主要作用是存储计算时的数据，你可能好奇为什么有了内存还需要寄存器？原因很简单，因为内存离 CPU 太远了，而寄存器就在 CPU 里，还紧挨着控制单元和逻辑运算单元，自然计算时速度会很快。
常见的寄存器种类：
通用寄存器，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。 程序计数器，用来存储 CPU 要执行下一条指令「所在的内存地址」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令的地址。 指令寄存器，用来存放程序计数器指向的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里。 总线 总线是用于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种：
地址总线，用于指定 CPU 将要操作的内存地址； 数据总线，用于读写内存的数据； 控制总线，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线； 当 CPU 要读写内存数据的时候，一般需要通过下面这三个总线：
首先要通过「地址总线」来指定内存的地址； 然后通过「控制总线」控制是读或写命令； 最后通过「数据总线」来传输数据； I/O设备 输入设备向计算机输入数据，计算机经过计算后，把数据输出给输出设备。期间，如果输入设备是键盘，按下按键时是需要和 CPU 进行交互的，这时就需要用到控制总线了。
程序执行基本过程 那 CPU 执行程序的过程如下：
第一步，CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个指令数据存入到「指令寄存器」。 第二步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执行； 第三步，CPU 执行完指令后，「程序计数器」的值自增，表示指向下一条指令。这个自增的大小，由 CPU 的位宽决定，比如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会自增 4； 简单总结一下就是，一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。
CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 CPU 的指令周期。
a=1+2的执行过程 知道了基本的程序执行过程后，接下来用 a = 1 + 2 的作为例子，进一步分析该程序在冯诺伊曼模型的执行过程。
CPU 是不认识 a = 1 + 2 这个字符串，这些字符串只是方便我们程序员认识，要想这段程序能跑起来，还需要把整个程序翻译成汇编语言的程序，这个过程称为编译成汇编代码。
针对汇编代码，我们还需要用汇编器翻译成机器码，这些机器码由 0 和 1 组成的机器语言，这一条条机器码，就是一条条的计算机指令，这个才是 CPU 能够真正认识的东西。
下面来看看 a = 1 + 2 在 32 位 CPU 的执行过程。
程序编译过程中，编译器通过分析代码，发现 1 和 2 是数据，于是程序运行时，内存会有个专门的区域来存放这些数据，这个区域就是「数据段」。如下图，数据 1 和 2 的区域位置：
数据 1 被存放到 0x100 位置； 数据 2 被存放到 0x104 位置； 注意，数据和指令是分开区域存放的，存放指令区域的地方称为「正文段」。
编译器会把 a = 1 + 2 翻译成 4 条指令，存放到正文段中。如图，这 4 条指令被存放到了 0x200 ~ 0x20c 的区域中：
0x200 的内容是 load 指令将 0x100 地址中的数据 1 装入到寄存器 R0； 0x204 的内容是 load 指令将 0x104 地址中的数据 2 装入到寄存器 R1； 0x208 的内容是 add 指令将寄存器 R0 和 R1 的数据相加，并把结果存放到寄存器 R2； 0x20c 的内容是 store 指令将寄存器 R2 中的数据存回数据段中的 0x108 地址中，这个地址也就是变量 a 内存中的地址； 编译完成后，具体执行程序的时候，程序计数器会被设置为 0x200 地址，然后依次执行这 4 条指令。
上面的例子中，由于是在 32 位 CPU 执行的，因此一条指令是占 32 位大小，所以你会发现每条指令间隔 4 个字节。
而数据的大小是根据你在程序中指定的变量类型，比如 int 类型的数据则占 4 个字节，char 类型的数据则占 1 个字节。
指令的执行速度 CPU 的硬件参数都会有 GHz 这个参数，比如一个 1 GHz 的 CPU，指的是时钟频率是 1 G，代表着 1 秒会产生 1G 次数的脉冲信号，每一次脉冲信号高低电平的转换就是一个周期，称为时钟周期。
对于 CPU 来说，在一个时钟周期内，CPU 仅能完成一个最基本的动作，时钟频率越高，时钟周期就越短，工作速度也就越快。
一个时钟周期一定能执行完一条指令吗？答案是不一定的，大多数指令不能在一个时钟周期完成，通常需要若干个时钟周期。不同的指令需要的时钟周期是不同的，加法和乘法都对应着一条 CPU 指令，但是乘法需要的时钟周期就要比加法多。
如何让程序跑的更快？
程序执行的时候，耗费的 CPU 时间少就说明程序是快的，对于程序的 CPU 执行时间，我们可以拆解成 CPU 时钟周期数（*CPU Cycles*）和时钟周期时间（*Clock Cycle Time*）的乘积。
时钟周期时间就是我们前面提及的 CPU 主频，主频越高说明 CPU 的工作速度就越快，比如我手头上的电脑的 CPU 是 2.4 GHz 四核 Intel Core i5，这里的 2.4 GHz 就是电脑的主频，时钟周期时间就是 1/2.4G。
要想 CPU 跑的更快，自然缩短时钟周期时间，也就是提升 CPU 主频，但是今非彼日，摩尔定律早已失效，当今的 CPU 主频已经很难再做到翻倍的效果了。
另外，换一个更好的 CPU，这个也是我们软件工程师控制不了的事情，我们应该把目光放到另外一个乘法因子 —— CPU 时钟周期数，如果能减少程序所需的 CPU 时钟周期数量，一样也是能提升程序的性能的。
对于 CPU 时钟周期数我们可以进一步拆解成：「指令数 x 每条指令的平均时钟周期数（*Cycles Per Instruction*，简称 CPI）」，于是程序的 CPU 执行时间的公式可变成如下：
因此，要想程序跑的更快，优化这三者即可：
指令数，表示执行程序所需要多少条指令，以及哪些指令。这个层面是基本靠编译器来优化，毕竟同样的代码，在不同的编译器，编译出来的计算机指令会有各种不同的表示方式。 每条指令的平均时钟周期数 CPI，表示一条指令需要多少个时钟周期数，现代大多数 CPU 通过流水线技术（Pipeline），让一条指令需要的 CPU 时钟周期数尽可能的少； 时钟周期时间，表示计算机主频，取决于计算机硬件。有的 CPU 支持超频技术，打开了超频意味着把 CPU 内部的时钟给调快了，于是 CPU 工作速度就变快了，但是也是有代价的，CPU 跑的越快，散热的压力就会越大，CPU 会很容易奔溃。 总结 64 位相比 32 位 CPU 的优势在哪吗？64 位 CPU 的计算性能一定比 32 位 CPU 高很多吗？
64 位相比 32 位 CPU 的优势主要体现在两个方面：
64 位 CPU 可以一次计算超过 32 位的数字，而 32 位 CPU 如果要计算超过 32 位的数字，要分多步骤进行计算，效率就没那么高，但是大部分应用程序很少会计算那么大的数字，所以只有运算大数字的时候，64 位 CPU 的优势才能体现出来，否则和 32 位 CPU 的计算性能相差不大。 64 位 CPU 可以寻址更大的内存空间，32 位 CPU 最大的寻址地址是 4G，即使你加了 8G 大小的内存，也还是只能寻址到 4G，而 64 位 CPU 最大寻址地址是 2^64，远超于 32 位 CPU 最大寻址地址的 2^32。 你知道软件的 32 位和 64 位之间的区别吗？再来 32 位的操作系统可以运行在 64 位的电脑上吗？64 位的操作系统可以运行在 32 位的电脑上吗？如果不行，原因是什么？
64 位和 32 位软件，实际上代表指令是 64 位还是 32 位的：
如果 32 位指令在 64 位机器上执行，需要一套兼容机制，就可以做到兼容运行了。但是如果 64 位指令在 32 位机器上执行，就比较困难了，因为 32 位的寄存器存不下 64 位的指令； 操作系统其实也是一种程序，我们也会看到操作系统会分成 32 位操作系统、64 位操作系统，其代表意义就是操作系统中程序的指令是多少位，比如 64 位操作系统，指令也就是 64 位，因此不能装在 32 位机器上。 总之，硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽。</content></entry><entry><title>计算机网络系列：一、键入网址到网页显示，期间发生了什么</title><url>https://yeplain.xyz/post/network/</url><categories><category>basic</category></categories><tags><tag>basic</tag></tags><content type="html">
计算机网络基本概念回顾笔记
网络分层 OSI 七层：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层
TCP/IP分为四层：应用层、传输层、网络层、网络接口层
TCP/IP五层：应用层、传输层、网络层、数据链路层、物理层
应用层 应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP等
应用层是工作在操作系统中的用户态，传输层及以下则工作在内核态
传输层 在传输层会有两个传输协议，分别是 TCP 和 UDP。
TCP 的全称叫传输控制协议（Transmission Control Protocol），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。
UDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP 传输协议，也不是一件简单的事情。
应用需要传输的数据可能会非常大，如果直接传输就不好控制，因此当传输层的数据包大小超过 MSS（TCP 最大报文段长度） ，就要将数据包分块，这样即使中途有一个分块丢失或损坏了，只需要重新发送这一个分块，而不用重新发送整个数据包。在 TCP 协议中，我们把每个分块称为一个 TCP 段（TCP Segment）
当设备作为接收方时，传输层则要负责把数据包传给应用，但是一台设备上可能会有很多应用在接收或者传输数据，因此需要用一个编号将应用区分开来，这个编号就是端口。
比如 80 端口通常是 Web 服务器用的，22 端口通常是远程登录服务器用的。而对于浏览器（客户端）中的每个标签栏都是一个独立的进程，操作系统会为这些进程分配临时的端口号。
由于传输层的报文中会携带端口号，因此接收方可以识别出该报文是发送给哪个应用。
网络层 网络层最常使用的是 IP 协议（Internet Protocol），IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会再次进行分片，得到一个即将发送到网络的 IP 报文。
网络层负责将数据从一个设备传输到另一个设备，世界上那么多设备，又该如何找到对方呢？因此，网络层需要有区分设备的编号。
我们一般用 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段（比如，192.168.100.1），每段是 8 位。只有一个单纯的 IP 地址虽然做到了区分设备，但是寻址起来就特别麻烦，全世界那么多台设备，难道一个一个去匹配？这显然不科学。
因此，需要将 IP 地址分成两种意义：
一个是网络号，负责标识该 IP 地址是属于哪个「子网」的； 一个是主机号，负责标识同一「子网」下的不同主机； 怎么分的呢？这需要配合子网掩码才能算出 IP 地址 的网络号和主机号。
举个例子，比如 10.100.122.0/24，后面的/24表示就是 255.255.255.0 子网掩码，255.255.255.0 二进制是「11111111-11111111-11111111-00000000」，大家数数一共多少个1？不用数了，是 24 个1，为了简化子网掩码的表示，用/24代替255.255.255.0。
知道了子网掩码，该怎么计算出网络地址和主机地址呢？
将 10.100.122.2 和 255.255.255.0 进行按位与运算，就可以得到网络号
将 255.255.255.0 取反后与IP地址进行进行按位与运算，就可以得到主机号
那么在寻址的过程中，先匹配到相同的网络号（表示要找到同一个子网），才会去找对应的主机。
除了寻址能力， IP 协议还有另一个重要的能力就是路由。实际场景中，两台设备并不是用一条网线连接起来的，而是通过很多网关、路由器、交换机等众多网络设备连接起来的，那么就会形成很多条网络的路径，因此当数据包到达一个网络节点，就需要通过路由算法决定下一步走哪条路径。
路由器寻址工作中，就是要找到目标地址的子网，找到后进而把数据包转发给对应的网络内。
路由器功能：分组转发、路由选择
网络接口层 IP 头部中的接收方 IP 地址表示网络包的目的地，通过这个地址我们就可以判断要将包发到哪里，但在以太网的世界中，这个思路是行不通的。
什么是以太网呢？电脑上的以太网接口，Wi-Fi接口，以太网交换机、路由器上的千兆，万兆以太网口，还有网线，它们都是以太网的组成部分。以太网就是一种在「局域网」内，把附近的设备连接起来，使它们之间可以进行通讯的技术。
以太网在判断网络包目的地时和 IP 的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而 MAC 头部就是干这个用的，所以，在以太网进行通讯要用到 MAC 地址。
MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。
所以说，网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。
键入网址到网页显示，期间发生了什么？ HTTP 首先浏览器做的第一步工作就是要对 URL 进行解析，从而生成发送给 Web 服务器的请求信息。
对 URL 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息了。
有两种请求形式： GET 和POST区别：
GET在浏览器回退时是无害的，而POST会再次提交请求。 GET产生的URL地址可以被Bookmark，而POST不可以。 GET请求会被浏览器主动cache，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 GET请求在URL中传送的参数是有长度限制的，而POST没有。 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 GET参数通过URL传递，POST放在Request body中 DNS 通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 Web 服务器。
但在发送之前，还有一项工作需要完成，那就是查询服务器域名对应的 IP 地址，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。
有一种服务器就专门保存了 Web 服务器域名与 IP 的对应关系，它就是 DNS 服务器。
域名解析流程 那是不是每次解析域名都要经过那么多的步骤呢？
当然不是了，还有缓存这个东西的嘛。
浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地 DNS 服务器」。
TCP 我们先看看 TCP 报文头部的格式：
首先，源端口号和目标端口号是不可少的，如果没有这两个端口号，数据就不知道应该发给哪个应用。
接下来有包的序号，这个是为了解决包乱序的问题。
还有应该有的是确认号，目的是确认发出去对方是否有收到。如果没有收到就应该重新发送，直到送达，这个是为了解决不丢包的问题。
接下来还有一些状态位。例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。
还有一个重要的就是窗口大小。TCP 要做流量控制，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。
除了做流量控制以外，TCP还会做拥塞控制，对于真正的通路堵车不堵车，它无能为力，唯一能做的就是控制自己，也即控制发送的速度。不能改变世界，就改变自己嘛。
TCP 传输数据之前，要先三次握手建立连接
在 HTTP 传输数据之前，首先需要 TCP 建立连接，TCP 连接的建立，通常称为三次握手。
一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。 然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。 服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。 客户端收到服务端发送的 SYN 和 ACK 之后，发送对 SYN 确认的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。 服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。 所以三次握手目的是保证双方都有发送和接收的能力。
TCP 分割数据
如果 HTTP 请求消息比较长，超过了 MSS 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。
MTU：一个网络包的最大长度，以太网中一般为 1500 字节。 MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。 数据会被以 MSS 的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。
TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 80， HTTPS 默认端口号是 443）。
在双方建立了连接后，TCP 报文中的数据部分就是存放 HTTP 头部 + 数据，组装好 TCP 报文之后，就需交给下面的网络层处理。
IP 我们先看看 IP 报文头部的格式：
在 IP 协议里面需要有源地址 IP 和 目标地址 IP：
源地址IP，即是客户端输出的 IP 地址； 目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。 因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的协议号，要填写为 06（十六进制），表示协议为 TCP。
MAC 生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 MAC 头部。
MAC 包头格式
MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息。
在 MAC 包头里需要发送方 MAC 地址和接收方目标 MAC 地址，用于两点之间的传输。
一般在 TCP/IP 通信里，MAC 包头的协议类型只使用：
0800 ： IP 协议 0806 ： ARP 协议 MAC 发送方和接收方如何确认?
发送方的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。
接收方的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的 MAC 地址。
所以先得搞清楚应该把包发给谁，这个只要查一下路由表就知道了。在路由表中找到相匹配的条目，然后把包发给 Gateway 列中的 IP 地址就可以了。
既然知道要发给谁，按如何获取对方的 MAC 地址呢？
此时就需要 ARP 协议帮我们找到路由器的 MAC 地址。
ARP 协议会在以太网中以广播的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。
然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。
如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。
好像每次都要广播获取，这不是很麻烦吗？
放心，在后续操作系统会把本次查询结果放到一块叫做 ARP 缓存的内存空间留着以后用，不过缓存的时间就几分钟。
也就是说，在发包时：
先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。 而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。 网卡（适配器） 网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将数字信息转换为电信号，才能在网线上传输，也就是说，这才是真正的数据发送过程。
负责执行这一操作的是网卡，要控制网卡还需要靠网卡驱动程序。
网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。
最后网卡会将包转为电信号，通过网线发送出去。
网卡作用：
数据的封装与解封 发送时将上一层传递来的数据加上首部和尾部，成为以太网的帧。接收时将以太网的帧剥去首部和尾部，然后送交上一层。
链路管理 主要通过CSMA/CD（Carrier Sense Multiple Access with Collision Detection，带冲突检测的载波监听多路访问）协议来实现。
数据编码与译码 即曼彻斯特编码与译码。其中曼彻斯特码，又称数字双向码、分相码或相位编码(PE)，一种常用的的二元码线路编码方式之一，被物理层使用来编码一个同步位流的时钟和数据。
交换机 位于数据链路层
下面来看一下包是如何通过交换机的。交换机的设计是将网络包原样转发到目的地。交换机工作在 MAC 层，也称为二层网络设备。
交换机的包接收操作
首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。
然后通过包末尾的 FCS 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。
计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，交换机的端口不具有 MAC 地址。
将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。
交换机的 MAC 地址表主要包含两个信息：
一个是设备的 MAC 地址， 另一个是该设备连接在交换机的哪个端口上。 交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口。
当 MAC 地址表找不到指定的 MAC 地址会怎么样？
地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。
这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。
这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。
有人会说：“这样做会发送多余的包，会不会造成网络拥塞呢？”
其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了。
局域网中每秒可以传输上千个包，多出一两个包并无大碍。
此外，如果接收方 MAC 地址是一个广播地址，那么交换机会将包发送到除源端口之外的所有端口。
路由器 路由器与交换机的区别
网络包经过交换机之后，现在到达了路由器，并在此被转发到下一个路由器或目标设备。
这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。
不过在具体的操作过程上，路由器和交换机是有区别的。
因为路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址； 而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有 MAC 地址。 路由器基本原理
路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。
当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去。
路由器的包接收操作
首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进行错误校验。
如果没问题则检查 MAC 头部中的接收方 MAC 地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。
总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。
查询路由表确定输出端口
完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。
MAC 头部的作用就是将包送达路由器，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会被丢弃。
接下来，路由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。
转发操作分为几个阶段，首先是查询路由表判断转发目标。
假设地址为 10.10.1.101 的计算机要向地址为 192.168.1.100 的服务器发送一个包，这个包先到达图中的路由器。
判断转发目标的第一步，就是根据包的接收方 IP 地址查询路由表中的目标地址栏，以找到相匹配的记录。
路由匹配和前面讲的一样，每个条目的子网掩码和 192.168.1.100 IP 做 &amp; 与运算后，得到的结果与对应条目的目标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续与下个条目进行路由匹配。
如第二条目的子网掩码 255.255.255.0 与 192.168.1.100 IP 做 &amp; 与运算后，得到结果是 192.168.1.0 ，这与第二条目的目标地址 192.168.1.0 匹配，该第二条目记录就会被作为转发目标。
实在找不到匹配路由时，就会选择默认路由，路由表中子网掩码为 0.0.0.0 的记录表示「默认路由」。
路由器的发送操作
接下来就会进入包的发送操作。
首先，我们需要根据路由表的网关列判断对方的地址。
如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，还未抵达终点，还需继续需要路由器转发。 如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明已抵达终点。 知道对方的 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。
路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。
接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 0800 （十六进制）表示 IP 协议。
网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。
发送出去的网络包会通过交换机到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。
接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。
可以发现，在网络包传输的过程中，源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址，因为需要 MAC 地址在以太网内进行两个设备之间的包传输。
互相扒皮 — 服务器 与 客户端 数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。
接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 TCP 协议。
于是，扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。
于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。
服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里。
HTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。
穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳。
最后跳到了客户端的城门把守的路由器，路由器扒开 IP 头部发现是要找城内的人，于是又把包发给了城内的交换机，再由交换机转发到客户端。
客户端收到了服务器的响应数据包后，同样也非常的高兴，客户能拆快递了！
于是，客户端开始扒皮，把收到的数据包的皮扒剩 HTTP 响应报文后，交给浏览器去渲染页面，一份特别的数据包快递，就这样显示出来了！
最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。</content></entry><entry><title>数据库系列：一、三大范式</title><url>https://yeplain.xyz/post/sql-learning/</url><categories><category>basic</category></categories><tags><tag>basic</tag></tags><content type="html">
数据库基本概念回顾笔记
数据库完整性 实体完整性 主码必须唯一
参照完整性 外码必须与参照表中的一致
用户自定义完整性 用户自定义的约束
规范化 关系也是一个二维表，每行对应一个元组，每列对应一个域，每列称为属性
若关系中的某一属性组的值能唯一地标识一个元组，则称该属性组为候选码（Candidate key）
若一个关系有多个候选码，则选定其中一个或多个为主码（Primary key）
候选码的多个属性称为主属性（Prime attribute），不包含在任何候选码中的属性称为非主属性
完全函数依赖和部分函数依赖
一个低一级范式的关系模式，通过模式分解可以转换为若干个高一级范式的关系模式的集合，这种过程就叫规范化
1NF 如果一关系模式r(R)的每个属性对应的域值都是不可分的(即原子的)，则称r(R)属于第一范式，记为r(R)Î1NF.
第一范式的目标是：将基本数据划分成称为实体集或表的逻辑单元，当设计好每个实体后，需要为其指定主码。
第一范式是对关系模式的最起码的要求。不满足第一范式的数据库模式不能称为关系数据库
2NF 若关系模式R∈1NF，并且每一个非主属性都完全函数依赖于任何一个候选码，则R∈2NF。
第二范式的目标：将只部分依赖于候选码（即依赖于候选码的部分属性）的非主属性移到其他表中。
S-L-C这个函数依赖图中非主属性Sdept和Sloc部分函数依赖于码(Sno, Cno)
将其分为两个表后使得非主属性对其各自的码都是完全函数依赖
2NF范式虽然消除了由于非主属性对候选码的部分依赖所引起的冗余及各种异常，但并没有排除传递依赖。因此，还需要对其进一步规范化
3NF 若R∈3NF，则每一个非主属性既不部分依赖于码也不传递依赖于码
第三范式的目标：去掉表中不直接依赖于候选码的非主属性
Sno→Sdept Sdept → Sno Sdept→Sloc 可得： Sno→Sloc，即S-L中存在非主属性对码的传递函数依 赖，S-L ∉ 3NF
采用投影分解法，把S-L分解为两个关系模式，以消除传递函数依赖：
BCNF 通常认为BCNF是修正的第三范式，有时也称为扩充的第三范式。
一个满足BCNF的关系模式有：
所有非主属性都完全函数依赖于每个候选码 所有的主属性都完全函数依赖于每个不包含它的候选码 没有任何属性完全函数依赖于非码的任何一组属性 BCNF范式排除了：
任何属性(包括主属性和非主属性)对候选码的部分依赖和传递依赖； 主属性之间的传递依赖。 例子：
关系模式STJ(S,T,J)中，S表示学生，T表示教师，J表示课程。每一教师只教一门课，
每门课有若干教师，某一学生选定某门课，就对应一个固定的教师。
由语义可得到函数依赖：(S,J)→T；(S,T)→J；T→J
因为没有任何非主属性对码传递依赖或部分依赖，
STJ ∈ 3NF。
因为T是决定因素，而T不包含码，所以STJ 不属于 BCNF 关系。
候选码可以有多个，如上面（S,J）和（S,T）都是候选码，包含在任一一个候选码中的属性称为主属性，那么S,J,T都是主属性,以上不满足“所有的主属性都完全函数依赖于每个不包含它的候选码”
总结：</content></entry><entry><title>Markdown语法手册</title><url>https://yeplain.xyz/post/zh-markdown-syntax/</url><categories/><tags/><content type="html"> 本文提供了一个可以在 Hugo 内容文件中使用的基本Markdown语法示例，还展示了基本 HTML 元素在 Hugo 主题中是否使用 CSS 装饰。
标题 下面的 HTML 代码&lt;h1>—&lt;h6> 元素表示六个级别的节标题。 &lt;h1>是最高的节级别，&lt;h6>是最低的节级别。
H1 H2 H3 H4 H5 H6 段落 生活是什么？生活是柴米油盐的平淡；是行色匆匆早出晚归的奔波；生活是错的时间遇到对的人的遗憾；是爱的付出与回报；生活是看不同的风景，遇到不同的人；是行至水穷尽，坐看云起时的峰回路转；生活是灵魂经历伤痛后的微笑怒放；是挫折坎坷被晾晒后的坚强；生活是酸甜苦辣被岁月沉淀后的馨香；是经历风霜雪雨洗礼后的懂得；生活是走遍千山万水后，回眸一笑的洒脱。
有些事，猝不及防，不管你在不在乎；有些人，并非所想，不管你明不明白；有些路，必须得走，不管你愿不愿意。不怕事，不惹事，不避事，做好自己，用真心面对一切；少埋怨，少指责，少发火，学会沉静，用微笑考量一切；多体察，多包容，多思索，尽心尽力，虽缺憾但无悔。像蒲公英一样美丽，虽轻盈，但并不卑微，它有自己的生命，也有自己的世界！
引用 blockquote 元素表示从另一个来源引用的内容，可选的引用必须在 footer 或 cite元素内，也可选的内嵌更改，如注释和缩写。
引用没有归属 读懂自我，带着简单的心情，看复杂的人生，走坎坷的路！
注意： 可以在块引用中使用 Markdown 语法。
带归属的引用 不要通过分享记忆来交流，通过交流来分享记忆。
— 罗布·派克1
表格 表不是Markdown核心规范的一部分，但是Hugo支持开箱即用。
Name Age Bob 27 Alice 23 表格内使用Markdown语法 Italics Bold Code italics bold code 图像 ![图像描述](图像地址) 示例 常规用法 SVG图像 Google Chrome
Firefox Browser
小图标 点击图像可以打开图像浏览器，快试试吧。
代码块 带有引号的代码块 &lt;!doctype html> &lt;html lang="en"> &lt;head> &lt;meta charset="utf-8"> &lt;title>Example HTML5 Document&lt;/title> &lt;/head> &lt;body> &lt;p>Test&lt;/p> &lt;/body> &lt;/html> 用四个空格缩进的代码块 &lt;!doctype html>
&lt;html lang="en">
&lt;head>
&lt;meta charset="utf-8">
&lt;title>Example HTML5 Document&lt;/title>
&lt;/head>
&lt;body>
&lt;p>Test&lt;/p>
&lt;/body>
&lt;/html>
代码块引用Hugo的内部高亮短代码 &lt;!doctype html> &lt;html lang="en"> &lt;head> &lt;meta charset="utf-8"> &lt;title>Example HTML5 Document&lt;/title> &lt;/head> &lt;body> &lt;p>Test&lt;/p> &lt;/body> &lt;/html> 列表类型 有序列表 First item Second item Third item 无序列表 List item Another item And another item 嵌套列表 Fruit Apple Orange Banana Dairy Milk Cheese 其他元素 — abbr, sub, sup, kbd, mark GIF 是位图图像格式。
H2O
Xn + Yn = Zn
按 CTRL+ALT+Delete 组合键结束会话。
大多数蝾螈在夜间活动，捕食昆虫、蠕虫和其他小动物。
以上引文摘自Rob Pike在2015年11月18日 Gopherfest 上的演讲
。&#160;&#8617;&#xfe0e;</content></entry><entry><title>富文本内容测试</title><url>https://yeplain.xyz/post/zh-rich-content/</url><categories/><tags/><content type="html"> Hugo 上有几个内置短码
，用于丰富内容，以及隐私配置
还有一组简单的短代码，支持各种社交媒体嵌入的静态和非 JS 版本。
YouTube 增强隐私短码 {{/&lt; youtube ZJthWmvUzzc >/}}
Twitter 短码 {{/&lt; twitter_simple 1085870671291310081 >/}}
Vimeo 短码 {{/&lt; vimeo_simple 48912912 >/}}
哔哩哔哩短码</content></entry><entry><title>图像占位符显示</title><url>https://yeplain.xyz/post/zh-placeholder-text/</url><categories/><tags/><content type="html"> 范德格拉夫原理（Van de Graaf Canon）重构了曾经用于书籍设计中将页面划分为舒适比例的方法。这一原理也被称为“秘密原理”，用于许多中世纪的手稿和古板书中。在范德格拉夫原理中，文本区域和页面的长款具有相同的比例，并且文本区域的高度等于页面宽度，通过划分页面得到九分之一的订口边距和九分之二的切口边距，以及与页面长宽相同的比例的文本区域。
Vagus 示例 The Van de Graaf Canon
总结 当然设计中的黄金比例是为人所熟知的，黄金分割的公式为a:b=b:(a+b)。这是指较小的两个矩形与较大的两个矩形以相同的组合方式相关联。黄金分割比例为1:1.618。</content></entry><entry><title>数据公式设置显示</title><url>https://yeplain.xyz/post/zh-math-typesetting/</url><categories/><tags/><content type="html"> Hugo 项目中的数学表示法可以通过使用第三方 JavaScript 库来实现。
在这个例子中，我们将使用 MathJax
创建一个文件 /content/en[zh-CN]/math.md
可以全局启用MathJax，请在项目配置中将参数math设置为true
或是在每页基础上启用MathJax，在内容文件中包括参数math: true
注意： 使用支持的TeX功能
的联机参考资料
例子 重复的分数 $$ \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} \equiv 1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {1+\frac{e^{-6\pi}} {1+\frac{e^{-8\pi}} {1+\cdots} } } } $$
总和记号 $$ \left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right) $$
几何级数之和 我把接下来的两个例子分成了几行，这样它在手机上表现得更好。这就是为什么它们包含 \displaystyle。
$$ \displaystyle\sum_{i=1}^{k+1}i $$
$$ \displaystyle= \left(\sum_{i=1}^{k}i\right) +(k+1) $$
$$ \displaystyle= \frac{k(k+1)}{2}+k+1 $$
$$ \displaystyle= \frac{k(k+1)+2(k+1)}{2} $$
$$ \displaystyle= \frac{(k+1)(k+2)}{2} $$
$$ \displaystyle= \frac{(k+1)((k+1)+1)}{2} $$
乘记号 $$ \displaystyle 1 + \frac{q^2}{(1-q)}+\frac{q^6}{(1-q)(1-q^2)}+\cdots = \displaystyle \prod_{j=0}^{\infty}\frac{1}{(1-q^{5j+2})(1-q^{5j+3})}, \displaystyle\text{ for }\lvert q\rvert &lt; 1. $$
随文数式 这是一些线性数学: $$ k_{n+1} = n^2 + k_n^2 - k_{n-1} $$ ， 然后是更多的文本。
希腊字母 $$ \Gamma\ \Delta\ \Theta\ \Lambda\ \Xi\ \Pi\ \Sigma\ \Upsilon\ \Phi\ \Psi\ \Omega \alpha\ \beta\ \gamma\ \delta\ \epsilon\ \zeta\ \eta\ \theta\ \iota\ \kappa\ \lambda\ \mu\ \nu\ \xi \ \omicron\ \pi\ \rho\ \sigma\ \tau\ \upsilon\ \phi\ \chi\ \psi\ \omega\ \varepsilon\ \vartheta\ \varpi\ \varrho\ \varsigma\ \varphi $$
箭头 $$ \gets\ \to\ \leftarrow\ \rightarrow\ \uparrow\ \Uparrow\ \downarrow\ \Downarrow\ \updownarrow\ \Updownarrow $$
$$ \Leftarrow\ \Rightarrow\ \leftrightarrow\ \Leftrightarrow\ \mapsto\ \hookleftarrow \leftharpoonup\ \leftharpoondown\ \rightleftharpoons\ \longleftarrow\ \Longleftarrow\ \longrightarrow $$
$$ \Longrightarrow\ \longleftrightarrow\ \Longleftrightarrow\ \longmapsto\ \hookrightarrow\ \rightharpoonup $$
$$ \rightharpoondown\ \leadsto\ \nearrow\ \searrow\ \swarrow\ \nwarrow $$
符号 $$ \surd\ \barwedge\ \veebar\ \odot\ \oplus\ \otimes\ \oslash\ \circledcirc\ \boxdot\ \bigtriangleup $$
$$ \bigtriangledown\ \dagger\ \diamond\ \star\ \triangleleft\ \triangleright\ \angle\ \infty\ \prime\ \triangle $$
微积分学 $$ \int u \frac{dv}{dx},dx=uv-\int \frac{du}{dx}v,dx $$
$$ f(x) = \int_{-\infty}^\infty \hat f(\xi),e^{2 \pi i \xi x} $$
$$ \oint \vec{F} \cdot d\vec{s}=0 $$
洛伦茨方程 $$ \begin{aligned} \dot{x} &amp; = \sigma(y-x) \ \dot{y} &amp; = \rho x - y - xz \ \dot{z} &amp; = -\beta z + xy \end{aligned} $$
交叉乘积 这在KaTeX中是可行的，但在这种环境中馏分的分离不是很好。
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
这里有一个解决方案:使用“mfrac”类(在MathJax情况下没有区别)的额外类使分数更小:
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
强调 $$ \hat{x}\ \vec{x}\ \ddot{x} $$
有弹性的括号 $$ \left(\frac{x^2}{y^3}\right) $$
评估范围 $$ \left.\frac{x^3}{3}\right|_0^1 $$
诊断标准 $$ f(n) = \begin{cases} \frac{n}{2}, &amp; \text{if } n\text{ is even} \ 3n+1, &amp; \text{if } n\text{ is odd} \end{cases} $$
麦克斯韦方程组 $$ \begin{aligned} \nabla \times \vec{\mathbf{B}} -, \frac1c, \frac{\partial\vec{\mathbf{E}}}{\partial t} &amp; = \frac{4\pi}{c}\vec{\mathbf{j}} \ \nabla \cdot \vec{\mathbf{E}} &amp; = 4 \pi \rho \ \nabla \times \vec{\mathbf{E}}, +, \frac1c, \frac{\partial\vec{\mathbf{B}}}{\partial t} &amp; = \vec{\mathbf{0}} \ \nabla \cdot \vec{\mathbf{B}} &amp; = 0 \end{aligned} $$
这些方程式很狭窄。我们可以使用(例如)添加垂直间距 [1em] 在每个换行符(\)之后。正如你在这里看到的：
$$ \begin{aligned} \nabla \times \vec{\mathbf{B}} -, \frac1c, \frac{\partial\vec{\mathbf{E}}}{\partial t} &amp; = \frac{4\pi}{c}\vec{\mathbf{j}} \[1em] \nabla \cdot \vec{\mathbf{E}} &amp; = 4 \pi \rho \[0.5em] \nabla \times \vec{\mathbf{E}}, +, \frac1c, \frac{\partial\vec{\mathbf{B}}}{\partial t} &amp; = \vec{\mathbf{0}} \[1em] \nabla \cdot \vec{\mathbf{B}} &amp; = 0 \end{aligned} $$
统计学 固定词组：
$$ \frac{n!}{k!(n-k)!} = {^n}C_k {n \choose k} $$
分数在分数 $$ \frac{\frac{1}{x}+\frac{1}{y}}{y-z} $$
ｎ次方根 $$ \sqrt[n]{1+x+x^2+x^3+\ldots} $$
矩阵 $$ \begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13}\ a_{21} &amp; a_{22} &amp; a_{23}\ a_{31} &amp; a_{32} &amp; a_{33} \end{pmatrix} \begin{bmatrix} 0 &amp; \cdots &amp; 0 \ \vdots &amp; \ddots &amp; \vdots \ 0 &amp; \cdots &amp; 0 \end{bmatrix} $$
标点符号 $$ f(x) = \sqrt{1+x} \quad (x \ge -1) f(x) \sim x^2 \quad (x\to\infty) $$
现在用标点符号:
$$ f(x) = \sqrt{1+x}, \quad x \ge -1 f(x) \sim x^2, \quad x\to\infty $$</content></entry><entry><title>支持Emoji表情符号</title><url>https://yeplain.xyz/post/zh-emoji-support/</url><categories/><tags/><content type="html"> Emoji 表情符号可以通过多种方式在 Hugo 项目中启用。
使用 Emoji 表情符号可以在模板中可以直接调用 emojify
函数或是通过 内联短代码
来实现。
如果要全局启用 Emoji 表情符号，请在网站配置
文件中将 enableEmoji 参数值设置为 true，然后可以直接在内容文件中输入表情符号简写代码，参考如下：
猴子表情 🙈 :see_no_evil:
🙉 :hear_no_evil:
🙊 :speak_no_evil:
数字符号 1️⃣ :one:
2️⃣ :two:
3️⃣ :three:
建筑物 🏡 :house_with_garden:
🏣 :post_office:
🏥 :hospital:
更多的 Emoji 表情符号代码可参考Emoji 配对目录
。
注意: 以上步骤在 Hugo 中启用 Unicode 标准表情符号和序列，但是这些符号的呈现取决于浏览器和平台，要设置表情符号的样式，您可以使用第三方表情符号字体或字体。例如：
.emoji { font-family: Apple Color Emoji,Segoe UI Emoji,NotoColorEmoji,Segoe UI Symbol,Android Emoji,EmojiSymbols; }</content></entry><entry><title>关于我</title><url>https://yeplain.xyz/about.html</url><categories/><tags/><content type="html"> 编辑中·······</content></entry></search>